["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/micromark/lib/initialize/document.js"],"~:js","shadow$provide.module$node_modules$micromark$lib$initialize$document=function(global,require,module,exports){Object.defineProperty(exports,\"__esModule\",{value:!0});exports.document=void 0;var _micromarkFactorySpace=require(\"module$node_modules$micromark_factory_space$index\"),_micromarkUtilCharacter=require(\"module$node_modules$micromark_util_character$index\"),_micromarkUtilChunked=require(\"module$node_modules$micromark_util_chunked$index\");exports.document={tokenize:function(effects){function start(code){if(continued<\nstack.length){const item=stack[continued];self.containerState=item[1];return effects.attempt(item[0].continuation,documentContinue,checkNewContainers)(code)}return checkNewContainers(code)}function documentContinue(code){continued++;if(self.containerState._closeFlow){self.containerState._closeFlow=void 0;childFlow&&closeFlow();const indexBeforeExits=self.events.length;let indexBeforeFlow=indexBeforeExits,point;for(;indexBeforeFlow--;)if(\"exit\"===self.events[indexBeforeFlow][0]&&\"chunkFlow\"===self.events[indexBeforeFlow][1].type){point=\nself.events[indexBeforeFlow][1].end;break}exitContainers(continued);let index=indexBeforeExits;for(;index<self.events.length;)self.events[index][1].end=Object.assign({},point),index++;(0,_micromarkUtilChunked.splice)(self.events,indexBeforeFlow+1,0,self.events.slice(indexBeforeExits));self.events.length=index;return checkNewContainers(code)}return start(code)}function checkNewContainers(code){if(continued===stack.length){if(!childFlow)return documentContinued(code);if(childFlow.currentConstruct&&\nchildFlow.currentConstruct.concrete)return flowStart(code);self.interrupt=!(!childFlow.currentConstruct||childFlow._gfmTableDynamicInterruptHack)}self.containerState={};return effects.check(containerConstruct,thereIsANewContainer,thereIsNoNewContainer)(code)}function thereIsANewContainer(code){childFlow&&closeFlow();exitContainers(continued);return documentContinued(code)}function thereIsNoNewContainer(code){self.parser.lazy[self.now().line]=continued!==stack.length;lineStartOffset=self.now().offset;\nreturn flowStart(code)}function documentContinued(code){self.containerState={};return effects.attempt(containerConstruct,containerContinue,flowStart)(code)}function containerContinue(code){continued++;stack.push([self.currentConstruct,self.containerState]);return documentContinued(code)}function flowStart(code){if(null===code)childFlow&&closeFlow(),exitContainers(0),effects.consume(code);else return childFlow=childFlow||self.parser.flow(self.now()),effects.enter(\"chunkFlow\",{contentType:\"flow\",previous:childToken,\n_tokenizer:childFlow}),flowContinue(code)}function flowContinue(code){if(null===code)writeToChild(effects.exit(\"chunkFlow\"),!0),exitContainers(0),effects.consume(code);else{if((0,_micromarkUtilCharacter.markdownLineEnding)(code))return effects.consume(code),writeToChild(effects.exit(\"chunkFlow\")),continued=0,self.interrupt=void 0,start;effects.consume(code);return flowContinue}}function writeToChild(token,eof){var stream=self.sliceStream(token);eof&&stream.push(null);if(token.previous=childToken)childToken.next=\ntoken;childToken=token;childFlow.defineSkip(token.start);childFlow.write(stream);if(self.parser.lazy[token.start.line]){for(token=childFlow.events.length;token--;)if(childFlow.events[token][1].start.offset<lineStartOffset&&(!childFlow.events[token][1].end||childFlow.events[token][1].end.offset>lineStartOffset))return;stream=eof=self.events.length;let seen,point;for(;stream--;)if(\"exit\"===self.events[stream][0]&&\"chunkFlow\"===self.events[stream][1].type){if(seen){point=self.events[stream][1].end;break}seen=\n!0}exitContainers(continued);for(token=eof;token<self.events.length;)self.events[token][1].end=Object.assign({},point),token++;(0,_micromarkUtilChunked.splice)(self.events,stream+1,0,self.events.slice(eof));self.events.length=token}}function exitContainers(size){let index=stack.length;for(;index-- >size;){const entry=stack[index];self.containerState=entry[1];entry[0].exit.call(self,effects)}stack.length=size}function closeFlow(){childFlow.write([null]);childFlow=childToken=void 0;self.containerState._closeFlow=\nvoid 0}const self=this,stack=[];let continued=0,childFlow,childToken,lineStartOffset;return start}};const containerConstruct={tokenize:function(effects,ok,nok){return(0,_micromarkFactorySpace.factorySpace)(effects,effects.attempt(this.parser.constructs.document,ok,nok),\"linePrefix\",this.parser.constructs.disable.null.includes(\"codeIndented\")?void 0:4)}}}","~:source","shadow$provide[\"module$node_modules$micromark$lib$initialize$document\"] = function(global,require,module,exports) {\n\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.document = void 0;\n\nvar _micromarkFactorySpace = require(\"micromark-factory-space\");\n\nvar _micromarkUtilCharacter = require(\"micromark-util-character\");\n\nvar _micromarkUtilChunked = require(\"micromark-util-chunked\");\n\n/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Point} Point\n */\n\n/**\n * @typedef {Record<string, unknown>} StackState\n * @typedef {[Construct, StackState]} StackItem\n */\n\n/** @type {InitialConstruct} */\nconst document = {\n  tokenize: initializeDocument\n};\n/** @type {Construct} */\n\nexports.document = document;\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n/** @type {Initializer} */\n\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext|undefined} */\n\n  let childFlow;\n  /** @type {Token|undefined} */\n\n  let childToken;\n  /** @type {number} */\n\n  let lineStartOffset;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    } // Done.\n\n\n    return checkNewContainers(code);\n  }\n  /** @type {State} */\n\n\n  function documentContinue(code) {\n    continued++; // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n\n      if (childFlow) {\n        closeFlow();\n      } // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n\n\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point|undefined} */\n\n      let point; // Find the flow chunk.\n\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === 'chunkFlow') {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n\n      exitContainers(continued); // Fix positions.\n\n      let index = indexBeforeExits;\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point);\n        index++;\n      } // Inject the exits earlier (they’re still also at the end).\n\n\n      (0, _micromarkUtilChunked.splice)(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits)); // Discard the duplicate exits.\n\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n\n    return start(code);\n  }\n  /** @type {State} */\n\n\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      } // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n\n\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      } // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n\n\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    } // Check if there is a new container.\n\n\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n  /** @type {State} */\n\n\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n  /** @type {State} */\n\n\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n  /** @type {State} */\n\n\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n  /** @type {State} */\n\n\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]); // Try another.\n\n    return documentContinued(code);\n  }\n  /** @type {State} */\n\n\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    });\n    return flowContinue(code);\n  }\n  /** @type {State} */\n\n\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n\n    if ((0, _micromarkUtilCharacter.markdownLineEnding)(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit('chunkFlow')); // Get ready for the next line.\n\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n\n    effects.consume(code);\n    return flowContinue;\n  }\n  /**\n   * @param {Token} token\n   * @param {boolean} [eof]\n   * @returns {void}\n   */\n\n\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token);\n    if (eof) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream); // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n\n      while (index--) {\n        if ( // The token starts before the line ending…\n        childFlow.events[index][1].start.offset < lineStartOffset && (!childFlow.events[index][1].end || // …or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return;\n        }\n      } // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n\n\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean|undefined} */\n\n      let seen;\n      /** @type {Point|undefined} */\n\n      let point; // Find the previous chunk (the one before the lazy line).\n\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === 'chunkFlow') {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n\n          seen = true;\n        }\n      }\n\n      exitContainers(continued); // Fix positions.\n\n      index = indexBeforeExits;\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point);\n        index++;\n      } // Inject the exits earlier (they’re still also at the end).\n\n\n      (0, _micromarkUtilChunked.splice)(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits)); // Discard the duplicate exits.\n\n      self.events.length = index;\n    }\n  }\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n\n\n  function exitContainers(size) {\n    let index = stack.length; // Exit open containers.\n\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n\n    stack.length = size;\n  }\n\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeContainer(effects, ok, nok) {\n  return (0, _micromarkFactorySpace.factorySpace)(effects, effects.attempt(this.parser.constructs.document, ok, nok), 'linePrefix', this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$module$node_modules$micromark_util_character$index","~$shadow.js","~$module$node_modules$micromark_util_chunked$index","~$module$node_modules$micromark_factory_space$index"]],"~:properties",["^5",["next","tokenize","__esModule","document","value","previous","length","_tokenizer","interrupt","contentType","_closeFlow","containerState","end"]],"~:compiled-at",1676665867262,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$micromark$lib$initialize$document.js\",\n\"lineCount\":9,\n\"mappings\":\"AAAAA,cAAA,CAAA,qDAAA,CAA0E,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAGlHC,MAAOC,CAAAA,cAAP,CAAsBF,OAAtB,CAA+B,YAA/B,CAA6C,CAC3CG,MAAO,CAAA,CADoC,CAA7C,CAGAH,QAAQI,CAAAA,QAAR,CAAmB,IAAK,EAExB,KAAIC,uBAAyBP,OAAA,CAAQ,mDAAR,CAA7B,CAEIQ,wBAA0BR,OAAA,CAAQ,oDAAR,CAF9B,CAIIS,sBAAwBT,OAAA,CAAQ,kDAAR,CAwB5BE,QAAQI,CAAAA,QAAR,CALiBA,CACfI,SAUFC,QAA2B,CAACC,OAAD,CAAU,CAkBnCC,QAASA,MAAK,CAACC,IAAD,CAAO,CAWnB,GAAIC,SAAJ;AAAgBC,KAAMC,CAAAA,MAAtB,CAA8B,CAC5B,MAAMC,KAAOF,KAAA,CAAMD,SAAN,CACbI,KAAKC,CAAAA,cAAL,CAAsBF,IAAA,CAAK,CAAL,CACtB,OAAON,QAAQS,CAAAA,OAAR,CAAgBH,IAAA,CAAK,CAAL,CAAQI,CAAAA,YAAxB,CAAsCC,gBAAtC,CAAwDC,kBAAxD,CAAA,CAA4EV,IAA5E,CAHqB,CAO9B,MAAOU,mBAAA,CAAmBV,IAAnB,CAlBY,CAuBrBS,QAASA,iBAAgB,CAACT,IAAD,CAAO,CAC9BC,SAAA,EAIA,IAAII,IAAKC,CAAAA,cAAeK,CAAAA,UAAxB,CAAoC,CAClCN,IAAKC,CAAAA,cAAeK,CAAAA,UAApB,CAAiCC,IAAAA,EAE7BC,UAAJ,EACEC,SAAA,EAKF,OAAMC,iBAAmBV,IAAKW,CAAAA,MAAOb,CAAAA,MACrC,KAAIc,gBAAkBF,gBAAtB,CAGIG,KAEJ,KAAA,CAAOD,eAAA,EAAP,CAAA,CACE,GAAwC,MAAxC,GAAIZ,IAAKW,CAAAA,MAAL,CAAYC,eAAZ,CAAA,CAA6B,CAA7B,CAAJ,EAA2F,WAA3F,GAAkDZ,IAAKW,CAAAA,MAAL,CAAYC,eAAZ,CAAA,CAA6B,CAA7B,CAAgCE,CAAAA,IAAlF,CAAwG,CACtGD,KAAA;AAAQb,IAAKW,CAAAA,MAAL,CAAYC,eAAZ,CAAA,CAA6B,CAA7B,CAAgCG,CAAAA,GACxC,MAFsG,CAM1GC,cAAA,CAAepB,SAAf,CAEA,KAAIqB,MAAQP,gBAEZ,KAAA,CAAOO,KAAP,CAAejB,IAAKW,CAAAA,MAAOb,CAAAA,MAA3B,CAAA,CACEE,IAAKW,CAAAA,MAAL,CAAYM,KAAZ,CAAA,CAAmB,CAAnB,CAAsBF,CAAAA,GACtB,CAD4B/B,MAAOkC,CAAAA,MAAP,CAAc,EAAd,CAAkBL,KAAlB,CAC5B,CAAAI,KAAA,EAIF,IAAI3B,qBAAsB6B,CAAAA,MAA1B,EAAkCnB,IAAKW,CAAAA,MAAvC,CAA+CC,eAA/C,CAAiE,CAAjE,CAAoE,CAApE,CAAuEZ,IAAKW,CAAAA,MAAOS,CAAAA,KAAZ,CAAkBV,gBAAlB,CAAvE,CAEAV,KAAKW,CAAAA,MAAOb,CAAAA,MAAZ,CAAqBmB,KACrB,OAAOZ,mBAAA,CAAmBV,IAAnB,CAnC2B,CAsCpC,MAAOD,MAAA,CAAMC,IAAN,CA3CuB,CAgDhCU,QAASA,mBAAkB,CAACV,IAAD,CAAO,CAMhC,GAAIC,SAAJ,GAAkBC,KAAMC,CAAAA,MAAxB,CAAgC,CAI9B,GAAI,CAACU,SAAL,CACE,MAAOa,kBAAA,CAAkB1B,IAAlB,CAMT,IAAIa,SAAUc,CAAAA,gBAAd;AAAkCd,SAAUc,CAAAA,gBAAiBC,CAAAA,QAA7D,CACE,MAAOC,UAAA,CAAU7B,IAAV,CAMTK,KAAKyB,CAAAA,SAAL,CAAiB,EAAkBH,CAAVd,SAAUc,CAAAA,gBAAlB,EAAuCd,SAAUkB,CAAAA,6BAAjD,CAlBa,CAsBhC1B,IAAKC,CAAAA,cAAL,CAAsB,EACtB,OAAOR,QAAQkC,CAAAA,KAAR,CAAcC,kBAAd,CAAkCC,oBAAlC,CAAwDC,qBAAxD,CAAA,CAA+EnC,IAA/E,CA7ByB,CAkClCkC,QAASA,qBAAoB,CAAClC,IAAD,CAAO,CAC9Ba,SAAJ,EAAeC,SAAA,EACfO,eAAA,CAAepB,SAAf,CACA,OAAOyB,kBAAA,CAAkB1B,IAAlB,CAH2B,CAQpCmC,QAASA,sBAAqB,CAACnC,IAAD,CAAO,CACnCK,IAAK+B,CAAAA,MAAOC,CAAAA,IAAZ,CAAiBhC,IAAKiC,CAAAA,GAAL,EAAWC,CAAAA,IAA5B,CAAA,CAAoCtC,SAApC,GAAkDC,KAAMC,CAAAA,MACxDqC,gBAAA,CAAkBnC,IAAKiC,CAAAA,GAAL,EAAWG,CAAAA,MAC7B;MAAOZ,UAAA,CAAU7B,IAAV,CAH4B,CAQrC0B,QAASA,kBAAiB,CAAC1B,IAAD,CAAO,CAE/BK,IAAKC,CAAAA,cAAL,CAAsB,EACtB,OAAOR,QAAQS,CAAAA,OAAR,CAAgB0B,kBAAhB,CAAoCS,iBAApC,CAAuDb,SAAvD,CAAA,CAAkE7B,IAAlE,CAHwB,CAQjC0C,QAASA,kBAAiB,CAAC1C,IAAD,CAAO,CAC/BC,SAAA,EACAC,MAAMyC,CAAAA,IAAN,CAAW,CAACtC,IAAKsB,CAAAA,gBAAN,CAAwBtB,IAAKC,CAAAA,cAA7B,CAAX,CAEA,OAAOoB,kBAAA,CAAkB1B,IAAlB,CAJwB,CASjC6B,QAASA,UAAS,CAAC7B,IAAD,CAAO,CACvB,GAAa,IAAb,GAAIA,IAAJ,CACMa,SAEJ,EAFeC,SAAA,EAEf,CADAO,cAAA,CAAe,CAAf,CACA,CAAAvB,OAAQ8C,CAAAA,OAAR,CAAgB5C,IAAhB,CAHF,KAaA,OANAa,UAMO,CANKA,SAML,EANkBR,IAAK+B,CAAAA,MAAOS,CAAAA,IAAZ,CAAiBxC,IAAKiC,CAAAA,GAAL,EAAjB,CAMlB,CALPxC,OAAQgD,CAAAA,KAAR,CAAc,WAAd,CAA2B,CACzBC,YAAa,MADY,CAEzBC,SAAUC,UAFe;AAGzBC,WAAYrC,SAHa,CAA3B,CAKO,CAAAsC,YAAA,CAAanD,IAAb,CAdgB,CAmBzBmD,QAASA,aAAY,CAACnD,IAAD,CAAO,CAC1B,GAAa,IAAb,GAAIA,IAAJ,CACEoD,YAAA,CAAatD,OAAQuD,CAAAA,IAAR,CAAa,WAAb,CAAb,CAAwC,CAAA,CAAxC,CAEA,CADAhC,cAAA,CAAe,CAAf,CACA,CAAAvB,OAAQ8C,CAAAA,OAAR,CAAgB5C,IAAhB,CAHF,KAAA,CAOA,GAAI,GAAIN,uBAAwB4D,CAAAA,kBAA5B,EAAgDtD,IAAhD,CAAJ,CAME,MALAF,QAAQ8C,CAAAA,OAAR,CAAgB5C,IAAhB,CAKOD,CAJPqD,YAAA,CAAatD,OAAQuD,CAAAA,IAAR,CAAa,WAAb,CAAb,CAIOtD,CAFPE,SAEOF,CAFK,CAELA,CADPM,IAAKyB,CAAAA,SACE/B,CADUa,IAAAA,EACVb,CAAAA,KAGTD,QAAQ8C,CAAAA,OAAR,CAAgB5C,IAAhB,CACA,OAAOmD,aAjBP,CAD0B,CA2B5BC,QAASA,aAAY,CAACG,KAAD,CAAQC,GAAR,CAAa,CAChC,IAAMC,OAASpD,IAAKqD,CAAAA,WAAL,CAAiBH,KAAjB,CACXC,IAAJ,EAASC,MAAOd,CAAAA,IAAP,CAAY,IAAZ,CAET,IADAY,KAAMP,CAAAA,QACN,CADiBC,UACjB,CAAgBA,UAAWU,CAAAA,IAAX;AAAkBJ,KAClCN,WAAA,CAAaM,KACb1C,UAAU+C,CAAAA,UAAV,CAAqBL,KAAMxD,CAAAA,KAA3B,CACAc,UAAUgD,CAAAA,KAAV,CAAgBJ,MAAhB,CAkCA,IAAIpD,IAAK+B,CAAAA,MAAOC,CAAAA,IAAZ,CAAiBkB,KAAMxD,CAAAA,KAAMwC,CAAAA,IAA7B,CAAJ,CAAwC,CAGtC,IAFIjB,KAEJ,CAFYT,SAAUG,CAAAA,MAAOb,CAAAA,MAE7B,CAAOmB,KAAA,EAAP,CAAA,CACE,GACAT,SAAUG,CAAAA,MAAV,CAAiBM,KAAjB,CAAA,CAAwB,CAAxB,CAA2BvB,CAAAA,KAAM0C,CAAAA,MADjC,CAC0CD,eAD1C,GAC8D,CAAC3B,SAAUG,CAAAA,MAAV,CAAiBM,KAAjB,CAAA,CAAwB,CAAxB,CAA2BF,CAAAA,GAD1F,EAEAP,SAAUG,CAAAA,MAAV,CAAiBM,KAAjB,CAAA,CAAwB,CAAxB,CAA2BF,CAAAA,GAAIqB,CAAAA,MAF/B,CAEwCD,eAFxC,EAKE,MAOAvB,OAAAA,CADEF,GACFE,CADqBZ,IAAKW,CAAAA,MAAOb,CAAAA,MAIrC,KAAI2D,IAAJ,CAGI5C,KAEJ,KAAA,CAAOD,MAAA,EAAP,CAAA,CACE,GAAwC,MAAxC,GAAIZ,IAAKW,CAAAA,MAAL,CAAYC,MAAZ,CAAA,CAA6B,CAA7B,CAAJ,EAA2F,WAA3F,GAAkDZ,IAAKW,CAAAA,MAAL,CAAYC,MAAZ,CAAA,CAA6B,CAA7B,CAAgCE,CAAAA,IAAlF,CAAwG,CACtG,GAAI2C,IAAJ,CAAU,CACR5C,KAAA,CAAQb,IAAKW,CAAAA,MAAL,CAAYC,MAAZ,CAAA,CAA6B,CAA7B,CAAgCG,CAAAA,GACxC,MAFQ,CAKV0C,IAAA;AAAO,CAAA,CAN+F,CAU1GzC,cAAA,CAAepB,SAAf,CAIA,KAFAqB,KAEA,CAFQP,GAER,CAAOO,KAAP,CAAejB,IAAKW,CAAAA,MAAOb,CAAAA,MAA3B,CAAA,CACEE,IAAKW,CAAAA,MAAL,CAAYM,KAAZ,CAAA,CAAmB,CAAnB,CAAsBF,CAAAA,GACtB,CAD4B/B,MAAOkC,CAAAA,MAAP,CAAc,EAAd,CAAkBL,KAAlB,CAC5B,CAAAI,KAAA,EAIF,IAAI3B,qBAAsB6B,CAAAA,MAA1B,EAAkCnB,IAAKW,CAAAA,MAAvC,CAA+CC,MAA/C,CAAiE,CAAjE,CAAoE,CAApE,CAAuEZ,IAAKW,CAAAA,MAAOS,CAAAA,KAAZ,CAAkBV,GAAlB,CAAvE,CAEAV,KAAKW,CAAAA,MAAOb,CAAAA,MAAZ,CAAqBmB,KA/CiB,CAzCR,CAiGlCD,QAASA,eAAc,CAAC0C,IAAD,CAAO,CAC5B,IAAIzC,MAAQpB,KAAMC,CAAAA,MAElB,KAAA,CAAOmB,KAAA,EAAP,EAAiByC,IAAjB,CAAA,CAAuB,CACrB,MAAMC,MAAQ9D,KAAA,CAAMoB,KAAN,CACdjB,KAAKC,CAAAA,cAAL,CAAsB0D,KAAA,CAAM,CAAN,CACtBA,MAAA,CAAM,CAAN,CAASX,CAAAA,IAAKY,CAAAA,IAAd,CAAmB5D,IAAnB,CAAyBP,OAAzB,CAHqB,CAMvBI,KAAMC,CAAAA,MAAN,CAAe4D,IATa,CAY9BjD,QAASA,UAAS,EAAG,CACnBD,SAAUgD,CAAAA,KAAV,CAAgB,CAAC,IAAD,CAAhB,CAEAhD,UAAA,CADAoC,UACA,CADarC,IAAAA,EAEbP,KAAKC,CAAAA,cAAeK,CAAAA,UAApB;AAAiCC,IAAAA,EAJd,CAtTrB,MAAMP,KAAO,IAAb,CAGMH,MAAQ,EACd,KAAID,UAAY,CAAhB,CAGIY,SAHJ,CAMIoC,UANJ,CASIT,eACJ,OAAOzC,MAf4B,CAXpBP,CAMjB,OAAMyC,mBAAqB,CACzBrC,SAqUFsE,QAA0B,CAACpE,OAAD,CAAUqE,EAAV,CAAcC,GAAd,CAAmB,CAC3C,MAAO,GAAI3E,sBAAuB4E,CAAAA,YAA3B,EAAyCvE,OAAzC,CAAkDA,OAAQS,CAAAA,OAAR,CAAgB,IAAK6B,CAAAA,MAAOkC,CAAAA,UAAW9E,CAAAA,QAAvC,CAAiD2E,EAAjD,CAAqDC,GAArD,CAAlD,CAA6G,YAA7G,CAA2H,IAAKhC,CAAAA,MAAOkC,CAAAA,UAAWC,CAAAA,OAAQC,CAAAA,IAAKC,CAAAA,QAApC,CAA6C,cAA7C,CAAA,CAA+D7D,IAAAA,EAA/D,CAA2E,CAAtM,CADoC,CAtUlB,CArCuF;\",\n\"sources\":[\"node_modules/micromark/lib/initialize/document.js\"],\n\"sourcesContent\":[\"shadow$provide[\\\"module$node_modules$micromark$lib$initialize$document\\\"] = function(global,require,module,exports) {\\n\\\"use strict\\\";\\n\\nObject.defineProperty(exports, \\\"__esModule\\\", {\\n  value: true\\n});\\nexports.document = void 0;\\n\\nvar _micromarkFactorySpace = require(\\\"micromark-factory-space\\\");\\n\\nvar _micromarkUtilCharacter = require(\\\"micromark-util-character\\\");\\n\\nvar _micromarkUtilChunked = require(\\\"micromark-util-chunked\\\");\\n\\n/**\\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\\n * @typedef {import('micromark-util-types').Initializer} Initializer\\n * @typedef {import('micromark-util-types').Construct} Construct\\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\\n * @typedef {import('micromark-util-types').Token} Token\\n * @typedef {import('micromark-util-types').State} State\\n * @typedef {import('micromark-util-types').Point} Point\\n */\\n\\n/**\\n * @typedef {Record<string, unknown>} StackState\\n * @typedef {[Construct, StackState]} StackItem\\n */\\n\\n/** @type {InitialConstruct} */\\nconst document = {\\n  tokenize: initializeDocument\\n};\\n/** @type {Construct} */\\n\\nexports.document = document;\\nconst containerConstruct = {\\n  tokenize: tokenizeContainer\\n};\\n/** @type {Initializer} */\\n\\nfunction initializeDocument(effects) {\\n  const self = this;\\n  /** @type {Array<StackItem>} */\\n\\n  const stack = [];\\n  let continued = 0;\\n  /** @type {TokenizeContext|undefined} */\\n\\n  let childFlow;\\n  /** @type {Token|undefined} */\\n\\n  let childToken;\\n  /** @type {number} */\\n\\n  let lineStartOffset;\\n  return start;\\n  /** @type {State} */\\n\\n  function start(code) {\\n    // First we iterate through the open blocks, starting with the root\\n    // document, and descending through last children down to the last open\\n    // block.\\n    // Each block imposes a condition that the line must satisfy if the block is\\n    // to remain open.\\n    // For example, a block quote requires a `>` character.\\n    // A paragraph requires a non-blank line.\\n    // In this phase we may match all or just some of the open blocks.\\n    // But we cannot close unmatched blocks yet, because we may have a lazy\\n    // continuation line.\\n    if (continued < stack.length) {\\n      const item = stack[continued];\\n      self.containerState = item[1];\\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\\n    } // Done.\\n\\n\\n    return checkNewContainers(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function documentContinue(code) {\\n    continued++; // Note: this field is called `_closeFlow` but it also closes containers.\\n    // Perhaps a good idea to rename it but it\\u2019s already used in the wild by\\n    // extensions.\\n\\n    if (self.containerState._closeFlow) {\\n      self.containerState._closeFlow = undefined;\\n\\n      if (childFlow) {\\n        closeFlow();\\n      } // Note: this algorithm for moving events around is similar to the\\n      // algorithm when dealing with lazy lines in `writeToChild`.\\n\\n\\n      const indexBeforeExits = self.events.length;\\n      let indexBeforeFlow = indexBeforeExits;\\n      /** @type {Point|undefined} */\\n\\n      let point; // Find the flow chunk.\\n\\n      while (indexBeforeFlow--) {\\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === 'chunkFlow') {\\n          point = self.events[indexBeforeFlow][1].end;\\n          break;\\n        }\\n      }\\n\\n      exitContainers(continued); // Fix positions.\\n\\n      let index = indexBeforeExits;\\n\\n      while (index < self.events.length) {\\n        self.events[index][1].end = Object.assign({}, point);\\n        index++;\\n      } // Inject the exits earlier (they\\u2019re still also at the end).\\n\\n\\n      (0, _micromarkUtilChunked.splice)(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits)); // Discard the duplicate exits.\\n\\n      self.events.length = index;\\n      return checkNewContainers(code);\\n    }\\n\\n    return start(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function checkNewContainers(code) {\\n    // Next, after consuming the continuation markers for existing blocks, we\\n    // look for new block starts (e.g. `>` for a block quote).\\n    // If we encounter a new block start, we close any blocks unmatched in\\n    // step 1 before creating the new block as a child of the last matched\\n    // block.\\n    if (continued === stack.length) {\\n      // No need to `check` whether there\\u2019s a container, of `exitContainers`\\n      // would be moot.\\n      // We can instead immediately `attempt` to parse one.\\n      if (!childFlow) {\\n        return documentContinued(code);\\n      } // If we have concrete content, such as block HTML or fenced code,\\n      // we can\\u2019t have containers \\u201cpierce\\u201d into them, so we can immediately\\n      // start.\\n\\n\\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\\n        return flowStart(code);\\n      } // If we do have flow, it could still be a blank line,\\n      // but we\\u2019d be interrupting it w/ a new container if there\\u2019s a current\\n      // construct.\\n\\n\\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\\n    } // Check if there is a new container.\\n\\n\\n    self.containerState = {};\\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function thereIsANewContainer(code) {\\n    if (childFlow) closeFlow();\\n    exitContainers(continued);\\n    return documentContinued(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function thereIsNoNewContainer(code) {\\n    self.parser.lazy[self.now().line] = continued !== stack.length;\\n    lineStartOffset = self.now().offset;\\n    return flowStart(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function documentContinued(code) {\\n    // Try new containers.\\n    self.containerState = {};\\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function containerContinue(code) {\\n    continued++;\\n    stack.push([self.currentConstruct, self.containerState]); // Try another.\\n\\n    return documentContinued(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function flowStart(code) {\\n    if (code === null) {\\n      if (childFlow) closeFlow();\\n      exitContainers(0);\\n      effects.consume(code);\\n      return;\\n    }\\n\\n    childFlow = childFlow || self.parser.flow(self.now());\\n    effects.enter('chunkFlow', {\\n      contentType: 'flow',\\n      previous: childToken,\\n      _tokenizer: childFlow\\n    });\\n    return flowContinue(code);\\n  }\\n  /** @type {State} */\\n\\n\\n  function flowContinue(code) {\\n    if (code === null) {\\n      writeToChild(effects.exit('chunkFlow'), true);\\n      exitContainers(0);\\n      effects.consume(code);\\n      return;\\n    }\\n\\n    if ((0, _micromarkUtilCharacter.markdownLineEnding)(code)) {\\n      effects.consume(code);\\n      writeToChild(effects.exit('chunkFlow')); // Get ready for the next line.\\n\\n      continued = 0;\\n      self.interrupt = undefined;\\n      return start;\\n    }\\n\\n    effects.consume(code);\\n    return flowContinue;\\n  }\\n  /**\\n   * @param {Token} token\\n   * @param {boolean} [eof]\\n   * @returns {void}\\n   */\\n\\n\\n  function writeToChild(token, eof) {\\n    const stream = self.sliceStream(token);\\n    if (eof) stream.push(null);\\n    token.previous = childToken;\\n    if (childToken) childToken.next = token;\\n    childToken = token;\\n    childFlow.defineSkip(token.start);\\n    childFlow.write(stream); // Alright, so we just added a lazy line:\\n    //\\n    // ```markdown\\n    // > a\\n    // b.\\n    //\\n    // Or:\\n    //\\n    // > ~~~c\\n    // d\\n    //\\n    // Or:\\n    //\\n    // > | e |\\n    // f\\n    // ```\\n    //\\n    // The construct in the second example (fenced code) does not accept lazy\\n    // lines, so it marked itself as done at the end of its first line, and\\n    // then the content construct parses `d`.\\n    // Most constructs in markdown match on the first line: if the first line\\n    // forms a construct, a non-lazy line can\\u2019t \\u201cunmake\\u201d it.\\n    //\\n    // The construct in the third example is potentially a GFM table, and\\n    // those are *weird*.\\n    // It *could* be a table, from the first line, if the following line\\n    // matches a condition.\\n    // In this case, that second line is lazy, which \\u201cunmakes\\u201d the first line\\n    // and turns the whole into one content block.\\n    //\\n    // We\\u2019ve now parsed the non-lazy and the lazy line, and can figure out\\n    // whether the lazy line started a new flow block.\\n    // If it did, we exit the current containers between the two flow blocks.\\n\\n    if (self.parser.lazy[token.start.line]) {\\n      let index = childFlow.events.length;\\n\\n      while (index--) {\\n        if ( // The token starts before the line ending\\u2026\\n        childFlow.events[index][1].start.offset < lineStartOffset && (!childFlow.events[index][1].end || // \\u2026or ends after it.\\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\\n          // Exit: there\\u2019s still something open, which means it\\u2019s a lazy line\\n          // part of something.\\n          return;\\n        }\\n      } // Note: this algorithm for moving events around is similar to the\\n      // algorithm when closing flow in `documentContinue`.\\n\\n\\n      const indexBeforeExits = self.events.length;\\n      let indexBeforeFlow = indexBeforeExits;\\n      /** @type {boolean|undefined} */\\n\\n      let seen;\\n      /** @type {Point|undefined} */\\n\\n      let point; // Find the previous chunk (the one before the lazy line).\\n\\n      while (indexBeforeFlow--) {\\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === 'chunkFlow') {\\n          if (seen) {\\n            point = self.events[indexBeforeFlow][1].end;\\n            break;\\n          }\\n\\n          seen = true;\\n        }\\n      }\\n\\n      exitContainers(continued); // Fix positions.\\n\\n      index = indexBeforeExits;\\n\\n      while (index < self.events.length) {\\n        self.events[index][1].end = Object.assign({}, point);\\n        index++;\\n      } // Inject the exits earlier (they\\u2019re still also at the end).\\n\\n\\n      (0, _micromarkUtilChunked.splice)(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits)); // Discard the duplicate exits.\\n\\n      self.events.length = index;\\n    }\\n  }\\n  /**\\n   * @param {number} size\\n   * @returns {void}\\n   */\\n\\n\\n  function exitContainers(size) {\\n    let index = stack.length; // Exit open containers.\\n\\n    while (index-- > size) {\\n      const entry = stack[index];\\n      self.containerState = entry[1];\\n      entry[0].exit.call(self, effects);\\n    }\\n\\n    stack.length = size;\\n  }\\n\\n  function closeFlow() {\\n    childFlow.write([null]);\\n    childToken = undefined;\\n    childFlow = undefined;\\n    self.containerState._closeFlow = undefined;\\n  }\\n}\\n/** @type {Tokenizer} */\\n\\n\\nfunction tokenizeContainer(effects, ok, nok) {\\n  return (0, _micromarkFactorySpace.factorySpace)(effects, effects.attempt(this.parser.constructs.document, ok, nok), 'linePrefix', this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\\n}\\n};\"],\n\"names\":[\"shadow$provide\",\"global\",\"require\",\"module\",\"exports\",\"Object\",\"defineProperty\",\"value\",\"document\",\"_micromarkFactorySpace\",\"_micromarkUtilCharacter\",\"_micromarkUtilChunked\",\"tokenize\",\"initializeDocument\",\"effects\",\"start\",\"code\",\"continued\",\"stack\",\"length\",\"item\",\"self\",\"containerState\",\"attempt\",\"continuation\",\"documentContinue\",\"checkNewContainers\",\"_closeFlow\",\"undefined\",\"childFlow\",\"closeFlow\",\"indexBeforeExits\",\"events\",\"indexBeforeFlow\",\"point\",\"type\",\"end\",\"exitContainers\",\"index\",\"assign\",\"splice\",\"slice\",\"documentContinued\",\"currentConstruct\",\"concrete\",\"flowStart\",\"interrupt\",\"_gfmTableDynamicInterruptHack\",\"check\",\"containerConstruct\",\"thereIsANewContainer\",\"thereIsNoNewContainer\",\"parser\",\"lazy\",\"now\",\"line\",\"lineStartOffset\",\"offset\",\"containerContinue\",\"push\",\"consume\",\"flow\",\"enter\",\"contentType\",\"previous\",\"childToken\",\"_tokenizer\",\"flowContinue\",\"writeToChild\",\"exit\",\"markdownLineEnding\",\"token\",\"eof\",\"stream\",\"sliceStream\",\"next\",\"defineSkip\",\"write\",\"seen\",\"size\",\"entry\",\"call\",\"tokenizeContainer\",\"ok\",\"nok\",\"factorySpace\",\"constructs\",\"disable\",\"null\",\"includes\"]\n}\n"]