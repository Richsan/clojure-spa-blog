["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/hast-util-raw/lib/index.js"],"~:js","shadow$provide.module$node_modules$hast_util_raw$lib$index=function(global,require,module,exports){function unknown(node){throw Error(\"Cannot compile `\"+node.type+\"` node\");}function documentMode(node){node=\"root\"===node.type?node.children[0]:node;return!(!node||\"doctype\"!==node.type&&(\"element\"!==node.type||\"html\"!==node.tagName))}function createParse5Location(node){const start=(0,_unistUtilPosition.pointStart)(node);node=(0,_unistUtilPosition.pointEnd)(node);return{startLine:start.line,startCol:start.column,\nstartOffset:start.offset,endLine:node.line,endCol:node.column,endOffset:node.offset}}Object.defineProperty(exports,\"__esModule\",{value:!0});exports.raw=void 0;var _index=function(obj){return obj&&obj.__esModule?obj:{default:obj}}(require(\"module$node_modules$parse5$lib$parser$index\")),_unistUtilPosition=require(\"module$node_modules$unist_util_position$index\"),_unistUtilVisit=require(\"module$node_modules$unist_util_visit$index\"),_hastUtilFromParse=require(\"module$node_modules$hast_util_from_parse5$index\"),\n_hastUtilToParse=require(\"module$node_modules$hast_util_to_parse5$index\"),_htmlVoidElements=require(\"module$node_modules$html_void_elements$index\"),_webNamespaces=require(\"module$node_modules$web_namespaces$index\"),_zwitch=require(\"module$node_modules$zwitch$index\");const parseOptions={sourceCodeLocationInfo:!0,scriptingEnabled:!1},raw=function(tree,file,options){function fragment(){const mock={nodeName:\"documentmock\",tagName:\"documentmock\",attrs:[],namespaceURI:_webNamespaces.webNamespaces.html,\nchildNodes:[]},doc={nodeName:\"#document-fragment\",childNodes:[]};parser._bootstrap(mock,{nodeName:\"template\",tagName:\"template\",attrs:[],namespaceURI:_webNamespaces.webNamespaces.html,childNodes:[]});parser._pushTmplInsertionMode(\"IN_TEMPLATE_MODE\");parser._initTokenizerForFragmentParsing();parser._insertFakeRootElement();parser._resetInsertionMode();parser._findFormInFragmentContext();tokenizer=parser.tokenizer;if(!tokenizer)throw Error(\"Expected `tokenizer`\");preprocessor=tokenizer.preprocessor;\nlocationTracker=tokenizer.__mixins[0];posTracker=locationTracker.posTracker;one(tree);resetTokenizer();parser._adoptNodes(mock.childNodes[0],doc);return doc}function document(){const doc=parser.treeAdapter.createDocument();parser._bootstrap(doc,void 0);tokenizer=parser.tokenizer;if(!tokenizer)throw Error(\"Expected `tokenizer`\");preprocessor=tokenizer.preprocessor;locationTracker=tokenizer.__mixins[0];posTracker=locationTracker.posTracker;one(tree);resetTokenizer();return doc}function all(nodes){let index=\n-1;if(nodes)for(;++index<nodes.length;)one(nodes[index])}function comment(node){resetTokenizer();parser._processInputToken({type:\"COMMENT_TOKEN\",data:node.value,location:createParse5Location(node)})}function stitch(node){stitches=!0;node=\"children\"in node?{...node,children:raw({type:\"root\",children:node.children},file,options).children}:{...node};comment({type:\"comment\",value:{stitch:node}})}function resetTokenizer(){if(!tokenizer)throw Error(\"Expected `tokenizer`\");if(!posTracker)throw Error(\"Expected `posTracker`\");\nconst token=tokenizer.currentCharacterToken;token&&(token.location.endLine=posTracker.line,token.location.endCol=posTracker.col+1,token.location.endOffset=posTracker.offset+1,parser._processInputToken(token));tokenizer.tokenQueue=[];tokenizer.state=\"DATA_STATE\";tokenizer.returnState=\"\";tokenizer.charRefCode=-1;tokenizer.tempBuff=[];tokenizer.lastStartTagName=\"\";tokenizer.consumedAfterSnapshot=-1;tokenizer.active=!1;tokenizer.currentCharacterToken=void 0;tokenizer.currentToken=void 0;tokenizer.currentAttr=\nvoid 0}var index$jscomp$0=-1;const parser=new _index.default(parseOptions),one=(0,_zwitch.zwitch)(\"type\",{handlers:{root:function(node){all(node.children)},element:function(node){resetTokenizer();var JSCompiler_temp_const=parser,JSCompiler_temp_const$jscomp$0=JSCompiler_temp_const._processInputToken;var JSCompiler_inline_result=Object.assign(createParse5Location(node));JSCompiler_inline_result.startTag=Object.assign({},JSCompiler_inline_result);JSCompiler_inline_result={type:\"START_TAG_TOKEN\",tagName:node.tagName,\nselfClosing:!1,attrs:(0,_hastUtilToParse.toParse5)({tagName:node.tagName,type:\"element\",properties:node.properties,children:[]}).attrs,location:JSCompiler_inline_result};JSCompiler_temp_const$jscomp$0.call(JSCompiler_temp_const,JSCompiler_inline_result);all(node.children);_htmlVoidElements.htmlVoidElements.includes(node.tagName)||(resetTokenizer(),JSCompiler_temp_const=parser,JSCompiler_temp_const$jscomp$0=JSCompiler_temp_const._processInputToken,JSCompiler_inline_result=Object.assign(createParse5Location(node)),\nJSCompiler_inline_result.startTag=Object.assign({},JSCompiler_inline_result),JSCompiler_temp_const$jscomp$0.call(JSCompiler_temp_const,{type:\"END_TAG_TOKEN\",tagName:node.tagName,attrs:[],location:JSCompiler_inline_result}))},text:function(node){resetTokenizer();parser._processInputToken({type:\"CHARACTER_TOKEN\",chars:node.value,location:createParse5Location(node)})},comment,doctype:function(node){resetTokenizer();parser._processInputToken({type:\"DOCTYPE_TOKEN\",name:\"html\",forceQuirks:!1,publicId:\"\",\nsystemId:\"\",location:createParse5Location(node)})},raw:function(node){var start=(0,_unistUtilPosition.pointStart)(node);const line=start.line||1,column=start.column||1;start=start.offset||0;if(!preprocessor)throw Error(\"Expected `preprocessor`\");if(!tokenizer)throw Error(\"Expected `tokenizer`\");if(!posTracker)throw Error(\"Expected `posTracker`\");if(!locationTracker)throw Error(\"Expected `locationTracker`\");preprocessor.html=void 0;preprocessor.pos=-1;preprocessor.lastGapPos=-1;preprocessor.lastCharPos=\n-1;preprocessor.gapStack=[];preprocessor.skipNextNewLine=!1;preprocessor.lastChunkWritten=!1;preprocessor.endOfChunkHit=!1;posTracker.isEol=!1;posTracker.lineStartPos=-column+1;posTracker.droppedBufferSize=start;posTracker.offset=0;posTracker.col=1;posTracker.line=line;locationTracker.currentAttrLocation=void 0;locationTracker.ctLoc=createParse5Location(node);tokenizer.write(node.value);parser._runParsingLoop(null);if(\"NAMED_CHARACTER_REFERENCE_STATE\"===tokenizer.state||\"NUMERIC_CHARACTER_REFERENCE_END_STATE\"===\ntokenizer.state)preprocessor.lastChunkWritten=!0,tokenizer[tokenizer.state](tokenizer._consume())}},unknown});let stitches,tokenizer,preprocessor,posTracker,locationTracker;!file||\"message\"in file&&\"messages\"in file||(options=file,file=void 0);if(options&&options.passThrough)for(;++index$jscomp$0<options.passThrough.length;)one.handlers[options.passThrough[index$jscomp$0]]=stitch;index$jscomp$0=(0,_hastUtilFromParse.fromParse5)(documentMode(tree)?document():fragment(),file);stitches&&(0,_unistUtilVisit.visit)(index$jscomp$0,\n\"comment\",(node,index,parent)=>{if(node.value.stitch&&null!==parent&&null!==index)return parent.children[index]=node.value.stitch,index});return\"root\"!==tree.type&&\"root\"===index$jscomp$0.type&&1===index$jscomp$0.children.length?index$jscomp$0.children[0]:index$jscomp$0};exports.raw=raw}","~:source","shadow$provide[\"module$node_modules$hast_util_raw$lib$index\"] = function(global,require,module,exports) {\n\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.raw = void 0;\n\nvar _index = _interopRequireDefault(require(\"parse5/lib/parser/index.js\"));\n\nvar _unistUtilPosition = require(\"unist-util-position\");\n\nvar _unistUtilVisit = require(\"unist-util-visit\");\n\nvar _hastUtilFromParse = require(\"hast-util-from-parse5\");\n\nvar _hastUtilToParse = require(\"hast-util-to-parse5\");\n\nvar _htmlVoidElements = require(\"html-void-elements\");\n\nvar _webNamespaces = require(\"web-namespaces\");\n\nvar _zwitch = require(\"zwitch\");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * @typedef {import('vfile').VFile} VFile\n * @typedef {import('parse5').Document} P5Document\n * @typedef {import('parse5').DocumentFragment} P5Fragment\n * @typedef {Omit<import('parse5').Element, 'parentNode'>} P5Element\n * @typedef {import('parse5').Attribute} P5Attribute\n * @typedef {Omit<import('parse5').Location, 'startOffset' | 'endOffset'> & {startOffset: number|undefined, endOffset: number|undefined}} P5Location\n * @typedef {import('parse5').ParserOptions} P5ParserOptions\n * @typedef {import('hast').Root} Root\n * @typedef {import('hast').DocType} Doctype\n * @typedef {import('hast').Element} Element\n * @typedef {import('hast').Text} Text\n * @typedef {import('hast').Comment} Comment\n * @typedef {import('hast').Content} Content\n * @typedef {Root|Content} Node\n * @typedef {import('../complex-types').Raw} Raw\n *\n * @typedef {Omit<Comment, 'value'> & {value: {stitch: Node}}} Stitch\n *\n * @typedef Options\n * @property {Array<string>} [passThrough]\n *   List of custom hast node types to pass through (keep) in hast.\n *   If the passed through nodes have children, those children are expected to\n *   be hast and will be handled.\n *\n * @typedef HiddenTokenizer\n * @property {Array<HiddenLocationTracker>} __mixins\n *   Way too simple, but works for us.\n * @property {HiddenPreprocessor} preprocessor\n * @property {(value: string) => void} write\n * @property {() => number} _consume\n * @property {Array<HiddenToken>} tokenQueue\n * @property {string} state\n * @property {string} returnState\n * @property {number} charRefCode\n * @property {Array<number>} tempBuff\n * @property {Function} _flushCodePointsConsumedAsCharacterReference\n * @property {string} lastStartTagName\n * @property {number} consumedAfterSnapshot\n * @property {boolean} active\n * @property {HiddenToken|undefined} currentCharacterToken\n * @property {HiddenToken|undefined} currentToken\n * @property {unknown} currentAttr\n * @property {Function} NAMED_CHARACTER_REFERENCE_STATE\n * @property {Function} NUMERIC_CHARACTER_REFERENCE_END_STATE\n *\n * @typedef {Record<string, unknown> & {location: P5Location}} HiddenToken\n *\n * @typedef HiddenPreprocessor\n * @property {string|undefined} html\n * @property {number} pos\n * @property {number} lastGapPos\n * @property {number} lastCharPos\n * @property {Array<number>} gapStack\n * @property {boolean} skipNextNewLine\n * @property {boolean} lastChunkWritten\n * @property {boolean} endOfChunkHit\n *\n * @typedef HiddenLocationTracker\n * @property {P5Location|undefined} currentAttrLocation\n * @property {P5Location} ctLoc\n * @property {HiddenPosTracker} posTracker\n *\n * @typedef HiddenPosTracker\n * @property {boolean} isEol\n * @property {number} lineStartPos\n * @property {number} droppedBufferSize\n * @property {number} offset\n * @property {number} col\n * @property {number} line\n */\n// @ts-expect-error: untyped.\nconst inTemplateMode = 'IN_TEMPLATE_MODE';\nconst dataState = 'DATA_STATE';\nconst characterToken = 'CHARACTER_TOKEN';\nconst startTagToken = 'START_TAG_TOKEN';\nconst endTagToken = 'END_TAG_TOKEN';\nconst commentToken = 'COMMENT_TOKEN';\nconst doctypeToken = 'DOCTYPE_TOKEN';\n/** @type {P5ParserOptions} */\n\nconst parseOptions = {\n  sourceCodeLocationInfo: true,\n  scriptingEnabled: false\n};\n/**\n * Given a hast tree and an optional vfile (for positional info), return a new\n * parsed-again hast tree.\n *\n * @param tree\n *   Original hast tree.\n * @param file\n *   Virtual file for positional info, optional.\n * @param options\n *   Configuration.\n */\n\nconst raw =\n/**\n * @param {Node} tree\n * @param {VFile} [file]\n * @param {Options} [options]\n */\nfunction (tree, file, options) {\n  let index = -1;\n  const parser = new _index.default(parseOptions);\n  const one = (0, _zwitch.zwitch)('type', {\n    handlers: {\n      root,\n      element,\n      text,\n      comment,\n      doctype,\n      raw: handleRaw\n    },\n    // @ts-expect-error: hush.\n    unknown\n  });\n  /** @type {boolean|undefined} */\n\n  let stitches;\n  /** @type {HiddenTokenizer|undefined} */\n\n  let tokenizer;\n  /** @type {HiddenPreprocessor|undefined} */\n\n  let preprocessor;\n  /** @type {HiddenPosTracker|undefined} */\n\n  let posTracker;\n  /** @type {HiddenLocationTracker|undefined} */\n\n  let locationTracker;\n\n  if (isOptions(file)) {\n    options = file;\n    file = undefined;\n  }\n\n  if (options && options.passThrough) {\n    while (++index < options.passThrough.length) {\n      // @ts-expect-error: hush.\n      one.handlers[options.passThrough[index]] = stitch;\n    }\n  }\n\n  const result = (0, _hastUtilFromParse.fromParse5)(documentMode(tree) ? document() : fragment(), file);\n\n  if (stitches) {\n    (0, _unistUtilVisit.visit)(result, 'comment', (node, index, parent) => {\n      const stitch = node;\n\n      if (stitch.value.stitch && parent !== null && index !== null) {\n        // @ts-expect-error: assume the stitch is allowed.\n        parent.children[index] = stitch.value.stitch;\n        return index;\n      }\n    });\n  } // Unpack if possible and when not given a `root`.\n\n\n  if (tree.type !== 'root' && result.type === 'root' && result.children.length === 1) {\n    return result.children[0];\n  }\n\n  return result;\n  /**\n   * @returns {P5Fragment}\n   */\n\n  function fragment() {\n    /** @type {P5Element} */\n    const context = {\n      nodeName: 'template',\n      tagName: 'template',\n      attrs: [],\n      namespaceURI: _webNamespaces.webNamespaces.html,\n      childNodes: []\n    };\n    /** @type {P5Element} */\n\n    const mock = {\n      nodeName: 'documentmock',\n      tagName: 'documentmock',\n      attrs: [],\n      namespaceURI: _webNamespaces.webNamespaces.html,\n      childNodes: []\n    };\n    /** @type {P5Fragment} */\n\n    const doc = {\n      nodeName: '#document-fragment',\n      childNodes: []\n    };\n\n    parser._bootstrap(mock, context);\n\n    parser._pushTmplInsertionMode(inTemplateMode);\n\n    parser._initTokenizerForFragmentParsing();\n\n    parser._insertFakeRootElement();\n\n    parser._resetInsertionMode();\n\n    parser._findFormInFragmentContext();\n\n    tokenizer = parser.tokenizer;\n    /* c8 ignore next */\n\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\n    preprocessor = tokenizer.preprocessor;\n    locationTracker = tokenizer.__mixins[0];\n    posTracker = locationTracker.posTracker;\n    one(tree);\n    resetTokenizer();\n\n    parser._adoptNodes(mock.childNodes[0], doc);\n\n    return doc;\n  }\n  /**\n   * @returns {P5Document}\n   */\n\n\n  function document() {\n    /** @type {P5Document} */\n    const doc = parser.treeAdapter.createDocument();\n\n    parser._bootstrap(doc, undefined);\n\n    tokenizer = parser.tokenizer;\n    /* c8 ignore next */\n\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\n    preprocessor = tokenizer.preprocessor;\n    locationTracker = tokenizer.__mixins[0];\n    posTracker = locationTracker.posTracker;\n    one(tree);\n    resetTokenizer();\n    return doc;\n  }\n  /**\n   * @param {Array<Content>} nodes\n   * @returns {void}\n   */\n\n\n  function all(nodes) {\n    let index = -1;\n    /* istanbul ignore else - invalid nodes, see rehypejs/rehype-raw#7. */\n\n    if (nodes) {\n      while (++index < nodes.length) {\n        one(nodes[index]);\n      }\n    }\n  }\n  /**\n   * @param {Root} node\n   * @returns {void}\n   */\n\n\n  function root(node) {\n    all(node.children);\n  }\n  /**\n   * @param {Element} node\n   * @returns {void}\n   */\n\n\n  function element(node) {\n    resetTokenizer();\n\n    parser._processInputToken(startTag(node));\n\n    all(node.children);\n\n    if (!_htmlVoidElements.htmlVoidElements.includes(node.tagName)) {\n      resetTokenizer();\n\n      parser._processInputToken(endTag(node));\n    }\n  }\n  /**\n   * @param {Text} node\n   * @returns {void}\n   */\n\n\n  function text(node) {\n    resetTokenizer();\n\n    parser._processInputToken({\n      type: characterToken,\n      chars: node.value,\n      location: createParse5Location(node)\n    });\n  }\n  /**\n   * @param {Doctype} node\n   * @returns {void}\n   */\n\n\n  function doctype(node) {\n    resetTokenizer();\n\n    parser._processInputToken({\n      type: doctypeToken,\n      name: 'html',\n      forceQuirks: false,\n      publicId: '',\n      systemId: '',\n      location: createParse5Location(node)\n    });\n  }\n  /**\n   * @param {Comment|Stitch} node\n   * @returns {void}\n   */\n\n\n  function comment(node) {\n    resetTokenizer();\n\n    parser._processInputToken({\n      type: commentToken,\n      data: node.value,\n      location: createParse5Location(node)\n    });\n  }\n  /**\n   * @param {Raw} node\n   * @returns {void}\n   */\n\n\n  function handleRaw(node) {\n    const start = (0, _unistUtilPosition.pointStart)(node);\n    const line = start.line || 1;\n    const column = start.column || 1;\n    const offset = start.offset || 0;\n    /* c8 ignore next 4 */\n\n    if (!preprocessor) throw new Error('Expected `preprocessor`');\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\n    if (!posTracker) throw new Error('Expected `posTracker`');\n    if (!locationTracker) throw new Error('Expected `locationTracker`'); // Reset preprocessor:\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/tokenizer/preprocessor.js#L17>.\n\n    preprocessor.html = undefined;\n    preprocessor.pos = -1;\n    preprocessor.lastGapPos = -1;\n    preprocessor.lastCharPos = -1;\n    preprocessor.gapStack = [];\n    preprocessor.skipNextNewLine = false;\n    preprocessor.lastChunkWritten = false;\n    preprocessor.endOfChunkHit = false; // Reset preprocessor mixin:\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/extensions/position-tracking/preprocessor-mixin.js>.\n\n    posTracker.isEol = false;\n    posTracker.lineStartPos = -column + 1; // Looks weird, but ensures we get correct positional info.\n\n    posTracker.droppedBufferSize = offset;\n    posTracker.offset = 0;\n    posTracker.col = 1;\n    posTracker.line = line; // Reset location tracker:\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/extensions/location-info/tokenizer-mixin.js>.\n\n    locationTracker.currentAttrLocation = undefined;\n    locationTracker.ctLoc = createParse5Location(node); // See the code for `parse` and `parseFragment`:\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/parser/index.js#L371>.\n\n    tokenizer.write(node.value);\n\n    parser._runParsingLoop(null); // Character references hang, so if we ended there, we need to flush\n    // those too.\n    // We reset the preprocessor as if the document ends here.\n    // Then one single call to the relevant state does the trick, parse5\n    // consumes the whole token.\n\n\n    if (tokenizer.state === 'NAMED_CHARACTER_REFERENCE_STATE' || tokenizer.state === 'NUMERIC_CHARACTER_REFERENCE_END_STATE') {\n      preprocessor.lastChunkWritten = true;\n      tokenizer[tokenizer.state](tokenizer._consume());\n    }\n  }\n  /**\n   * @param {Node} node\n   */\n\n\n  function stitch(node) {\n    stitches = true;\n    /** @type {Node} */\n\n    let clone; // Recurse, because to somewhat handle `[<x>]</x>` (where `[]` denotes the\n    // passed through node).\n\n    if ('children' in node) {\n      clone = { ...node,\n        children: raw({\n          type: 'root',\n          children: node.children\n        }, file, options // @ts-expect-error Assume a given parent yields a parent.\n        ).children\n      };\n    } else {\n      clone = { ...node\n      };\n    } // Hack: `value` is supposed to be a string, but as none of the tools\n    // (`parse5` or `hast-util-from-parse5`) looks at it, we can pass nodes\n    // through.\n\n\n    comment({\n      type: 'comment',\n      value: {\n        stitch: clone\n      }\n    });\n  }\n\n  function resetTokenizer() {\n    /* c8 ignore next 2 */\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\n    if (!posTracker) throw new Error('Expected `posTracker`'); // Process final characters if theyâ€™re still there after hibernating.\n    // Similar to:\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/extensions/location-info/tokenizer-mixin.js#L95>.\n\n    const token = tokenizer.currentCharacterToken;\n\n    if (token) {\n      token.location.endLine = posTracker.line;\n      token.location.endCol = posTracker.col + 1;\n      token.location.endOffset = posTracker.offset + 1;\n\n      parser._processInputToken(token);\n    } // Reset tokenizer:\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/tokenizer/index.js#L218-L234>.\n    // Especially putting it back in the `data` state is useful: some elements,\n    // like textareas and iframes, change the state.\n    // See GH-7.\n    // But also if broken HTML is in `raw`, and then a correct element is given.\n    // See GH-11.\n\n\n    tokenizer.tokenQueue = [];\n    tokenizer.state = dataState;\n    tokenizer.returnState = '';\n    tokenizer.charRefCode = -1;\n    tokenizer.tempBuff = [];\n    tokenizer.lastStartTagName = '';\n    tokenizer.consumedAfterSnapshot = -1;\n    tokenizer.active = false;\n    tokenizer.currentCharacterToken = undefined;\n    tokenizer.currentToken = undefined;\n    tokenizer.currentAttr = undefined;\n  }\n};\n/**\n * @param {Element} node\n * @returns {HiddenToken}\n */\n\n\nexports.raw = raw;\n\nfunction startTag(node) {\n  /** @type {P5Location} */\n  const location = Object.assign(createParse5Location(node)); // @ts-expect-error extra positional info.\n\n  location.startTag = Object.assign({}, location); // Untyped token.\n\n  return {\n    type: startTagToken,\n    tagName: node.tagName,\n    selfClosing: false,\n    attrs: attributes(node),\n    location\n  };\n}\n/**\n * @param {Element} node\n * @returns {Array<P5Attribute>}\n */\n\n\nfunction attributes(node) {\n  return (0, _hastUtilToParse.toParse5)({\n    tagName: node.tagName,\n    type: 'element',\n    properties: node.properties,\n    children: [] // @ts-expect-error Assume element.\n\n  }).attrs;\n}\n/**\n * @param {Element} node\n * @returns {HiddenToken}\n */\n\n\nfunction endTag(node) {\n  /** @type {P5Location} */\n  const location = Object.assign(createParse5Location(node)); // @ts-expect-error extra positional info.\n\n  location.startTag = Object.assign({}, location); // Untyped token.\n\n  return {\n    type: endTagToken,\n    tagName: node.tagName,\n    attrs: [],\n    location\n  };\n}\n/**\n * @param {Node} node\n */\n\n\nfunction unknown(node) {\n  throw new Error('Cannot compile `' + node.type + '` node');\n}\n/**\n * @param {Node} node\n * @returns {boolean}\n */\n\n\nfunction documentMode(node) {\n  const head = node.type === 'root' ? node.children[0] : node;\n  return Boolean(head && (head.type === 'doctype' || head.type === 'element' && head.tagName === 'html'));\n}\n/**\n * @param {Node|Stitch} node\n * @returns {P5Location}\n */\n\n\nfunction createParse5Location(node) {\n  const start = (0, _unistUtilPosition.pointStart)(node);\n  const end = (0, _unistUtilPosition.pointEnd)(node);\n  return {\n    startLine: start.line,\n    startCol: start.column,\n    startOffset: start.offset,\n    endLine: end.line,\n    endCol: end.column,\n    endOffset: end.offset\n  };\n}\n/**\n * @param {VFile|Options|undefined} value\n * @return {value is Options}\n */\n\n\nfunction isOptions(value) {\n  return Boolean(value && !('message' in value && 'messages' in value));\n}\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$module$node_modules$unist_util_visit$index","~$module$node_modules$unist_util_position$index","~$module$node_modules$hast_util_from_parse5$index","~$module$node_modules$parse5$lib$parser$index","~$shadow.js","~$module$node_modules$html_void_elements$index","~$module$node_modules$hast_util_to_parse5$index","~$module$node_modules$zwitch$index","~$module$node_modules$web_namespaces$index"]],"~:properties",["^5",["properties","ctLoc","currentToken","lastCharPos","systemId","attrs","pos","currentCharacterToken","charRefCode","sourceCodeLocationInfo","offset","currentAttrLocation","endLine","handlers","isEol","childNodes","chars","lastChunkWritten","children","__esModule","publicId","root","forceQuirks","currentAttr","lineStartPos","endOfChunkHit","endOffset","nodeName","element","name","consumedAfterSnapshot","value","gapStack","location","startOffset","startLine","col","skipNextNewLine","text","tokenQueue","scriptingEnabled","stitch","lastStartTagName","line","unknown","type","namespaceURI","tagName","state","returnState","lastGapPos","html","active","comment","raw","selfClosing","doctype","data","startCol","startTag","default","endCol","droppedBufferSize","tempBuff"]],"~:compiled-at",1676841365349,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$hast_util_raw$lib$index.js\",\n\"lineCount\":14,\n\"mappings\":\"AAAAA,cAAA,CAAA,2CAAA,CAAgE,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAuiBxGC,QAASA,QAAO,CAACC,IAAD,CAAO,CACrB,KAAUC,MAAJ,CAAU,kBAAV,CAA+BD,IAAKE,CAAAA,IAApC,CAA2C,QAA3C,CAAN,CADqB,CASvBC,QAASA,aAAY,CAACH,IAAD,CAAO,CACpBI,IAAAA,CAAqB,MAAd,GAAAJ,IAAKE,CAAAA,IAAL,CAAuBF,IAAKK,CAAAA,QAAL,CAAc,CAAd,CAAvB,CAA0CL,IACvD,OAAO,EAAQI,CAAAA,IAAR,EAA+B,SAA/B,GAAiBA,IAAKF,CAAAA,IAAtB,GAA0D,SAA1D,GAA4CE,IAAKF,CAAAA,IAAjD,EAAwF,MAAxF,GAAuEE,IAAKE,CAAAA,OAA5E,EAFmB,CAU5BC,QAASA,qBAAoB,CAACP,IAAD,CAAO,CAClC,MAAMQ,MAAQ,GAAIC,kBAAmBC,CAAAA,UAAvB,EAAmCV,IAAnC,CACRW,KAAAA,CAAM,GAAIF,kBAAmBG,CAAAA,QAAvB,EAAiCZ,IAAjC,CACZ,OAAO,CACLa,UAAWL,KAAMM,CAAAA,IADZ,CAELC,SAAUP,KAAMQ,CAAAA,MAFX;AAGLC,YAAaT,KAAMU,CAAAA,MAHd,CAILC,QAASR,IAAIG,CAAAA,IAJR,CAKLM,OAAQT,IAAIK,CAAAA,MALP,CAMLK,UAAWV,IAAIO,CAAAA,MANV,CAH2B,CAvjBpCI,MAAOC,CAAAA,cAAP,CAAsBzB,OAAtB,CAA+B,YAA/B,CAA6C,CAC3C0B,MAAO,CAAA,CADoC,CAA7C,CAGA1B,QAAQ2B,CAAAA,GAAR,CAAc,IAAK,EAEnB,KAAIC,OAgBJC,QAA+B,CAACC,GAAD,CAAM,CAAE,MAAOA,IAAA,EAAOA,GAAIC,CAAAA,UAAX,CAAwBD,GAAxB,CAA8B,CAAEE,QAASF,GAAX,CAAvC,CAhBxB,CAAuBhC,OAAA,CAAQ,6CAAR,CAAvB,CAAb,CAEIa,mBAAqBb,OAAA,CAAQ,+CAAR,CAFzB,CAIImC,gBAAkBnC,OAAA,CAAQ,4CAAR,CAJtB,CAMIoC,mBAAqBpC,OAAA,CAAQ,iDAAR,CANzB;AAQIqC,iBAAmBrC,OAAA,CAAQ,+CAAR,CARvB,CAUIsC,kBAAoBtC,OAAA,CAAQ,8CAAR,CAVxB,CAYIuC,eAAiBvC,OAAA,CAAQ,0CAAR,CAZrB,CAcIwC,QAAUxC,OAAA,CAAQ,kCAAR,CAqFd,OAAMyC,aAAe,CACnBC,uBAAwB,CAAA,CADL,CAEnBC,iBAAkB,CAAA,CAFC,CAArB,CAgBMd,IAMNA,QAAS,CAACe,IAAD,CAAOC,IAAP,CAAaC,OAAb,CAAsB,CAmE7BC,QAASA,SAAQ,EAAG,CAWlB,MAAMC,KAAO,CACXC,SAAU,cADC,CAEXvC,QAAS,cAFE,CAGXwC,MAAO,EAHI,CAIXC,aAAcZ,cAAea,CAAAA,aAAcC,CAAAA,IAJhC;AAKXC,WAAY,EALD,CAAb,CASMC,IAAM,CACVN,SAAU,oBADA,CAEVK,WAAY,EAFF,CAKZE,OAAOC,CAAAA,UAAP,CAAkBT,IAAlB,CAvBgBU,CACdT,SAAU,UADIS,CAEdhD,QAAS,UAFKgD,CAGdR,MAAO,EAHOQ,CAIdP,aAAcZ,cAAea,CAAAA,aAAcC,CAAAA,IAJ7BK,CAKdJ,WAAY,EALEI,CAuBhB,CAEAF,OAAOG,CAAAA,sBAAP,CA7HmBC,kBA6HnB,CAEAJ,OAAOK,CAAAA,gCAAP,EAEAL,OAAOM,CAAAA,sBAAP,EAEAN,OAAOO,CAAAA,mBAAP,EAEAP,OAAOQ,CAAAA,0BAAP,EAEAC,UAAA,CAAYT,MAAOS,CAAAA,SAGnB,IAAI,CAACA,SAAL,CAAgB,KAAU5D,MAAJ,CAAU,sBAAV,CAAN,CAChB6D,YAAA,CAAeD,SAAUC,CAAAA,YACzBC;eAAA,CAAkBF,SAAUG,CAAAA,QAAV,CAAmB,CAAnB,CAClBC,WAAA,CAAaF,eAAgBE,CAAAA,UAC7BC,IAAA,CAAI1B,IAAJ,CACA2B,eAAA,EAEAf,OAAOgB,CAAAA,WAAP,CAAmBxB,IAAKM,CAAAA,UAAL,CAAgB,CAAhB,CAAnB,CAAuCC,GAAvC,CAEA,OAAOA,IAjDW,CAwDpBkB,QAASA,SAAQ,EAAG,CAElB,MAAMlB,IAAMC,MAAOkB,CAAAA,WAAYC,CAAAA,cAAnB,EAEZnB,OAAOC,CAAAA,UAAP,CAAkBF,GAAlB,CAAuBqB,IAAAA,EAAvB,CAEAX,UAAA,CAAYT,MAAOS,CAAAA,SAGnB,IAAI,CAACA,SAAL,CAAgB,KAAU5D,MAAJ,CAAU,sBAAV,CAAN,CAChB6D,YAAA,CAAeD,SAAUC,CAAAA,YACzBC,gBAAA,CAAkBF,SAAUG,CAAAA,QAAV,CAAmB,CAAnB,CAClBC,WAAA,CAAaF,eAAgBE,CAAAA,UAC7BC,IAAA,CAAI1B,IAAJ,CACA2B,eAAA,EACA,OAAOhB,IAfW,CAuBpBsB,QAASA,IAAG,CAACC,KAAD,CAAQ,CAClB,IAAIC;AAAQ,CAAC,CAGb,IAAID,KAAJ,CACE,IAAA,CAAO,EAAEC,KAAT,CAAiBD,KAAME,CAAAA,MAAvB,CAAA,CACEV,GAAA,CAAIQ,KAAA,CAAMC,KAAN,CAAJ,CANc,CA6EpBE,QAASA,QAAO,CAAC7E,IAAD,CAAO,CACrBmE,cAAA,EAEAf,OAAO0B,CAAAA,kBAAP,CAA0B,CACxB5E,KA7Pe6E,eA4PS,CAExBC,KAAMhF,IAAKwB,CAAAA,KAFa,CAGxByD,SAAU1E,oBAAA,CAAqBP,IAArB,CAHc,CAA1B,CAHqB,CAsEvBkF,QAASA,OAAM,CAAClF,IAAD,CAAO,CACpBmF,QAAA,CAAW,CAAA,CAOTC,KAAA,CADE,UAAJ,EAAkBpF,KAAlB,CACU,CAAE,GAAGA,IAAL,CACNK,SAAUoB,GAAA,CAAI,CACZvB,KAAM,MADM,CAEZG,SAAUL,IAAKK,CAAAA,QAFH,CAAJ,CAGPoC,IAHO,CAGDC,OAHC,CAIRrC,CAAAA,QALI,CADV,CASU,CAAE,GAAGL,IAAL,CAOV6E,QAAA,CAAQ,CACN3E,KAAM,SADA,CAENsB,MAAO,CACL0D,OAAQE,IADH,CAFD,CAAR,CAvBoB,CA+BtBjB,QAASA,eAAc,EAAG,CAExB,GAAI,CAACN,SAAL,CAAgB,KAAU5D,MAAJ,CAAU,sBAAV,CAAN,CAChB,GAAI,CAACgE,UAAL,CAAiB,KAAUhE,MAAJ,CAAU,uBAAV,CAAN;AAIjB,MAAMoF,MAAQxB,SAAUyB,CAAAA,qBAEpBD,MAAJ,GACEA,KAAMJ,CAAAA,QAAS9D,CAAAA,OAIf,CAJyB8C,UAAWnD,CAAAA,IAIpC,CAHAuE,KAAMJ,CAAAA,QAAS7D,CAAAA,MAGf,CAHwB6C,UAAWsB,CAAAA,GAGnC,CAHyC,CAGzC,CAFAF,KAAMJ,CAAAA,QAAS5D,CAAAA,SAEf,CAF2B4C,UAAW/C,CAAAA,MAEtC,CAF+C,CAE/C,CAAAkC,MAAO0B,CAAAA,kBAAP,CAA0BO,KAA1B,CALF,CAeAxB,UAAU2B,CAAAA,UAAV,CAAuB,EACvB3B,UAAU4B,CAAAA,KAAV,CA3XcC,YA4Xd7B,UAAU8B,CAAAA,WAAV,CAAwB,EACxB9B,UAAU+B,CAAAA,WAAV,CAAwB,CAAC,CACzB/B,UAAUgC,CAAAA,QAAV,CAAqB,EACrBhC,UAAUiC,CAAAA,gBAAV,CAA6B,EAC7BjC,UAAUkC,CAAAA,qBAAV,CAAkC,CAAC,CACnClC,UAAUmC,CAAAA,MAAV,CAAmB,CAAA,CACnBnC,UAAUyB,CAAAA,qBAAV,CAAkCd,IAAAA,EAClCX,UAAUoC,CAAAA,YAAV,CAAyBzB,IAAAA,EACzBX,UAAUqC,CAAAA,WAAV;AAAwB1B,IAAAA,EAlCA,CAnU1B,IAAIG,eAAQ,CAAC,CACb,OAAMvB,OAAS,IAAI1B,MAAOI,CAAAA,OAAX,CAAmBO,YAAnB,CAAf,CACM6B,IAAM,GAAI9B,OAAQ+D,CAAAA,MAAZ,EAAoB,MAApB,CAA4B,CACtCC,SAAU,CACRC,KA6JJA,QAAa,CAACrG,IAAD,CAAO,CAClByE,GAAA,CAAIzE,IAAKK,CAAAA,QAAT,CADkB,CA9JR,CAERiG,QAqKJA,QAAgB,CAACtG,IAAD,CAAO,CACrBmE,cAAA,EAEAf,KAAAA,sBAAAA,MAAAA,CAAO0B,+BAAP1B,qBAAO0B,CAAAA,kBAqMHG,KAAAA,yBAAW3D,MAAOiF,CAAAA,MAAP,CAAchG,oBAAA,CArMMP,IAqMN,CAAd,CAEjBiF,yBAASuB,CAAAA,QAAT,CAAoBlF,MAAOiF,CAAAA,MAAP,CAAc,EAAd,CAAkBtB,wBAAlB,CAEpB,yBAAA,CAAO,CACL/E,KApZkBuG,iBAmZb,CAELnG,QA3MmCN,IA2MrBM,CAAAA,OAFT;AAGLoG,YAAa,CAAA,CAHR,CAIL5D,MAWK,GAAIb,gBAAiB0E,CAAAA,QAArB,EAA+B,CACpCrG,QAzNmCN,IAyNrBM,CAAAA,OADsB,CAEpCJ,KAAM,SAF8B,CAGpC0G,WA3NmC5G,IA2NlB4G,CAAAA,UAHmB,CAIpCvG,SAAU,EAJ0B,CAA/B,CAMJyC,CAAAA,KArBI,CAKLmC,SAAAA,wBALK,CAzMEH,+BAAP,CAAA,IAAA,CAAA1B,qBAAA,CAA0B,wBAA1B,CAEAqB,IAAA,CAAIzE,IAAKK,CAAAA,QAAT,CAEK6B,kBAAkB2E,CAAAA,gBAAiBC,CAAAA,QAAnC,CAA4C9G,IAAKM,CAAAA,OAAjD,CAAL,GACE6D,cAAA,EAEA,CAAAf,qBAAA,CAAAA,MAAA,CAAO0B,8BAAP,CAAA1B,qBAAO0B,CAAAA,kBAAP,CAiOEG,wBAjOF,CAiOa3D,MAAOiF,CAAAA,MAAP,CAAchG,oBAAA,CAjOMP,IAiON,CAAd,CAjOb;AAmOJiF,wBAASuB,CAAAA,QAnOL,CAmOgBlF,MAAOiF,CAAAA,MAAP,CAAc,EAAd,CAAkBtB,wBAAlB,CAnOhB,CAAOH,8BAAP,CAAA,IAAA,CAAA1B,qBAAA,CAqOG,CACLlD,KAtbgB6G,eAqbX,CAELzG,QAvOmCN,IAuOrBM,CAAAA,OAFT,CAGLwC,MAAO,EAHF,CAILmC,SAAAA,wBAJK,CArOH,CAHF,CAPqB,CAvKX,CAGR+B,KAuLJA,QAAa,CAAChH,IAAD,CAAO,CAClBmE,cAAA,EAEAf,OAAO0B,CAAAA,kBAAP,CAA0B,CACxB5E,KA/NiB+G,iBA8NO,CAExBC,MAAOlH,IAAKwB,CAAAA,KAFY,CAGxByD,SAAU1E,oBAAA,CAAqBP,IAArB,CAHc,CAA1B,CAHkB,CA1LR,CAIR6E,OAJQ,CAKRsC,QAoMJA,QAAgB,CAACnH,IAAD,CAAO,CACrBmE,cAAA,EAEAf,OAAO0B,CAAAA,kBAAP,CAA0B,CACxB5E,KA1OekH,eAyOS,CAExBC,KAAM,MAFkB,CAGxBC,YAAa,CAAA,CAHW,CAIxBC,SAAU,EAJc;AAKxBC,SAAU,EALc,CAMxBvC,SAAU1E,oBAAA,CAAqBP,IAArB,CANc,CAA1B,CAHqB,CAzMX,CAMRyB,IAoOJgG,QAAkB,CAACzH,IAAD,CAAO,CACvB,IAAMQ,MAAQ,GAAIC,kBAAmBC,CAAAA,UAAvB,EAAmCV,IAAnC,CACd,OAAMc,KAAON,KAAMM,CAAAA,IAAbA,EAAqB,CAA3B,CACME,OAASR,KAAMQ,CAAAA,MAAfA,EAAyB,CACzBE,MAAAA,CAASV,KAAMU,CAAAA,MAAfA,EAAyB,CAG/B,IAAI,CAAC4C,YAAL,CAAmB,KAAU7D,MAAJ,CAAU,yBAAV,CAAN,CACnB,GAAI,CAAC4D,SAAL,CAAgB,KAAU5D,MAAJ,CAAU,sBAAV,CAAN,CAChB,GAAI,CAACgE,UAAL,CAAiB,KAAUhE,MAAJ,CAAU,uBAAV,CAAN,CACjB,GAAI,CAAC8D,eAAL,CAAsB,KAAU9D,MAAJ,CAAU,4BAAV,CAAN,CAGtB6D,YAAab,CAAAA,IAAb,CAAoBuB,IAAAA,EACpBV,aAAa4D,CAAAA,GAAb,CAAmB,CAAC,CACpB5D,aAAa6D,CAAAA,UAAb,CAA0B,CAAC,CAC3B7D,aAAa8D,CAAAA,WAAb;AAA2B,CAAC,CAC5B9D,aAAa+D,CAAAA,QAAb,CAAwB,EACxB/D,aAAagE,CAAAA,eAAb,CAA+B,CAAA,CAC/BhE,aAAaiE,CAAAA,gBAAb,CAAgC,CAAA,CAChCjE,aAAakE,CAAAA,aAAb,CAA6B,CAAA,CAG7B/D,WAAWgE,CAAAA,KAAX,CAAmB,CAAA,CACnBhE,WAAWiE,CAAAA,YAAX,CAA0B,CAAClH,MAA3B,CAAoC,CAEpCiD,WAAWkE,CAAAA,iBAAX,CAA+BjH,KAC/B+C,WAAW/C,CAAAA,MAAX,CAAoB,CACpB+C,WAAWsB,CAAAA,GAAX,CAAiB,CACjBtB,WAAWnD,CAAAA,IAAX,CAAkBA,IAGlBiD,gBAAgBqE,CAAAA,mBAAhB,CAAsC5D,IAAAA,EACtCT,gBAAgBsE,CAAAA,KAAhB,CAAwB9H,oBAAA,CAAqBP,IAArB,CAGxB6D,UAAUyE,CAAAA,KAAV,CAAgBtI,IAAKwB,CAAAA,KAArB,CAEA4B,OAAOmF,CAAAA,eAAP,CAAuB,IAAvB,CAOA,IAAwB,iCAAxB,GAAI1E,SAAU4B,CAAAA,KAAd,EAAiF,uCAAjF;AAA6D5B,SAAU4B,CAAAA,KAAvE,CACE3B,YAAaiE,CAAAA,gBACb,CADgC,CAAA,CAChC,CAAAlE,SAAA,CAAUA,SAAU4B,CAAAA,KAApB,CAAA,CAA2B5B,SAAU2E,CAAAA,QAAV,EAA3B,CA/CqB,CA1Ob,CAD4B,CAUtCzI,OAVsC,CAA5B,CAcZ,KAAIoF,QAAJ,CAGItB,SAHJ,CAMIC,YANJ,CASIG,UATJ,CAYIF,eAEUtB,EAAAA,IAAd,EA6a0B,SA7a1B,EAAcA,KAAd,EA6agD,UA7ahD,EAAcA,KAAd,GACEC,OACA,CADUD,IACV,CAAAA,IAAA,CAAO+B,IAAAA,EAFT,CAKA,IAAI9B,OAAJ,EAAeA,OAAQ+F,CAAAA,WAAvB,CACE,IAAA,CAAO,EAAE9D,cAAT,CAAiBjC,OAAQ+F,CAAAA,WAAY7D,CAAAA,MAArC,CAAA,CAEEV,GAAIkC,CAAAA,QAAJ,CAAa1D,OAAQ+F,CAAAA,WAAR,CAAoB9D,cAApB,CAAb,CAAA,CAA2CO,MAIzCwD,eAAAA,CAAS,GAAI1G,kBAAmB2G,CAAAA,UAAvB,EAAmCxI,YAAA,CAAaqC,IAAb,CAAA,CAAqB6B,QAAA,EAArB,CAAkC1B,QAAA,EAArE,CAAiFF,IAAjF,CAEX0C,SAAJ,EACE,GAAIpD,eAAgB6G,CAAAA,KAApB,EAA2BF,cAA3B;AAAmC,SAAnC,CAA8C,CAAC1I,IAAD,CAAO2E,KAAP,CAAckE,MAAd,CAAA,EAAyB,CAGrE,GAFe7I,IAEJwB,CAAAA,KAAM0D,CAAAA,MAAjB,EAAsC,IAAtC,GAA2B2D,MAA3B,EAAwD,IAAxD,GAA8ClE,KAA9C,CAGE,MADAkE,OAAOxI,CAAAA,QAAP,CAAgBsE,KAAhB,CACOA,CALM3E,IAImBwB,CAAAA,KAAM0D,CAAAA,MAC/BP,CAAAA,KAN4D,CAAvE,CAYF,OAAkB,MAAlB,GAAInC,IAAKtC,CAAAA,IAAT,EAA4C,MAA5C,GAA4BwI,cAAOxI,CAAAA,IAAnC,EAAiF,CAAjF,GAAsDwI,cAAOrI,CAAAA,QAASuE,CAAAA,MAAtE,CACS8D,cAAOrI,CAAAA,QAAP,CAAgB,CAAhB,CADT,CAIOqI,cA9DsB,CA+W/B5I,QAAQ2B,CAAAA,GAAR,CAAcA,GAhf0F;\",\n\"sources\":[\"node_modules/hast-util-raw/lib/index.js\"],\n\"sourcesContent\":[\"shadow$provide[\\\"module$node_modules$hast_util_raw$lib$index\\\"] = function(global,require,module,exports) {\\n\\\"use strict\\\";\\n\\nObject.defineProperty(exports, \\\"__esModule\\\", {\\n  value: true\\n});\\nexports.raw = void 0;\\n\\nvar _index = _interopRequireDefault(require(\\\"parse5/lib/parser/index.js\\\"));\\n\\nvar _unistUtilPosition = require(\\\"unist-util-position\\\");\\n\\nvar _unistUtilVisit = require(\\\"unist-util-visit\\\");\\n\\nvar _hastUtilFromParse = require(\\\"hast-util-from-parse5\\\");\\n\\nvar _hastUtilToParse = require(\\\"hast-util-to-parse5\\\");\\n\\nvar _htmlVoidElements = require(\\\"html-void-elements\\\");\\n\\nvar _webNamespaces = require(\\\"web-namespaces\\\");\\n\\nvar _zwitch = require(\\\"zwitch\\\");\\n\\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\\n\\n/**\\n * @typedef {import('vfile').VFile} VFile\\n * @typedef {import('parse5').Document} P5Document\\n * @typedef {import('parse5').DocumentFragment} P5Fragment\\n * @typedef {Omit<import('parse5').Element, 'parentNode'>} P5Element\\n * @typedef {import('parse5').Attribute} P5Attribute\\n * @typedef {Omit<import('parse5').Location, 'startOffset' | 'endOffset'> & {startOffset: number|undefined, endOffset: number|undefined}} P5Location\\n * @typedef {import('parse5').ParserOptions} P5ParserOptions\\n * @typedef {import('hast').Root} Root\\n * @typedef {import('hast').DocType} Doctype\\n * @typedef {import('hast').Element} Element\\n * @typedef {import('hast').Text} Text\\n * @typedef {import('hast').Comment} Comment\\n * @typedef {import('hast').Content} Content\\n * @typedef {Root|Content} Node\\n * @typedef {import('../complex-types').Raw} Raw\\n *\\n * @typedef {Omit<Comment, 'value'> & {value: {stitch: Node}}} Stitch\\n *\\n * @typedef Options\\n * @property {Array<string>} [passThrough]\\n *   List of custom hast node types to pass through (keep) in hast.\\n *   If the passed through nodes have children, those children are expected to\\n *   be hast and will be handled.\\n *\\n * @typedef HiddenTokenizer\\n * @property {Array<HiddenLocationTracker>} __mixins\\n *   Way too simple, but works for us.\\n * @property {HiddenPreprocessor} preprocessor\\n * @property {(value: string) => void} write\\n * @property {() => number} _consume\\n * @property {Array<HiddenToken>} tokenQueue\\n * @property {string} state\\n * @property {string} returnState\\n * @property {number} charRefCode\\n * @property {Array<number>} tempBuff\\n * @property {Function} _flushCodePointsConsumedAsCharacterReference\\n * @property {string} lastStartTagName\\n * @property {number} consumedAfterSnapshot\\n * @property {boolean} active\\n * @property {HiddenToken|undefined} currentCharacterToken\\n * @property {HiddenToken|undefined} currentToken\\n * @property {unknown} currentAttr\\n * @property {Function} NAMED_CHARACTER_REFERENCE_STATE\\n * @property {Function} NUMERIC_CHARACTER_REFERENCE_END_STATE\\n *\\n * @typedef {Record<string, unknown> & {location: P5Location}} HiddenToken\\n *\\n * @typedef HiddenPreprocessor\\n * @property {string|undefined} html\\n * @property {number} pos\\n * @property {number} lastGapPos\\n * @property {number} lastCharPos\\n * @property {Array<number>} gapStack\\n * @property {boolean} skipNextNewLine\\n * @property {boolean} lastChunkWritten\\n * @property {boolean} endOfChunkHit\\n *\\n * @typedef HiddenLocationTracker\\n * @property {P5Location|undefined} currentAttrLocation\\n * @property {P5Location} ctLoc\\n * @property {HiddenPosTracker} posTracker\\n *\\n * @typedef HiddenPosTracker\\n * @property {boolean} isEol\\n * @property {number} lineStartPos\\n * @property {number} droppedBufferSize\\n * @property {number} offset\\n * @property {number} col\\n * @property {number} line\\n */\\n// @ts-expect-error: untyped.\\nconst inTemplateMode = 'IN_TEMPLATE_MODE';\\nconst dataState = 'DATA_STATE';\\nconst characterToken = 'CHARACTER_TOKEN';\\nconst startTagToken = 'START_TAG_TOKEN';\\nconst endTagToken = 'END_TAG_TOKEN';\\nconst commentToken = 'COMMENT_TOKEN';\\nconst doctypeToken = 'DOCTYPE_TOKEN';\\n/** @type {P5ParserOptions} */\\n\\nconst parseOptions = {\\n  sourceCodeLocationInfo: true,\\n  scriptingEnabled: false\\n};\\n/**\\n * Given a hast tree and an optional vfile (for positional info), return a new\\n * parsed-again hast tree.\\n *\\n * @param tree\\n *   Original hast tree.\\n * @param file\\n *   Virtual file for positional info, optional.\\n * @param options\\n *   Configuration.\\n */\\n\\nconst raw =\\n/**\\n * @param {Node} tree\\n * @param {VFile} [file]\\n * @param {Options} [options]\\n */\\nfunction (tree, file, options) {\\n  let index = -1;\\n  const parser = new _index.default(parseOptions);\\n  const one = (0, _zwitch.zwitch)('type', {\\n    handlers: {\\n      root,\\n      element,\\n      text,\\n      comment,\\n      doctype,\\n      raw: handleRaw\\n    },\\n    // @ts-expect-error: hush.\\n    unknown\\n  });\\n  /** @type {boolean|undefined} */\\n\\n  let stitches;\\n  /** @type {HiddenTokenizer|undefined} */\\n\\n  let tokenizer;\\n  /** @type {HiddenPreprocessor|undefined} */\\n\\n  let preprocessor;\\n  /** @type {HiddenPosTracker|undefined} */\\n\\n  let posTracker;\\n  /** @type {HiddenLocationTracker|undefined} */\\n\\n  let locationTracker;\\n\\n  if (isOptions(file)) {\\n    options = file;\\n    file = undefined;\\n  }\\n\\n  if (options && options.passThrough) {\\n    while (++index < options.passThrough.length) {\\n      // @ts-expect-error: hush.\\n      one.handlers[options.passThrough[index]] = stitch;\\n    }\\n  }\\n\\n  const result = (0, _hastUtilFromParse.fromParse5)(documentMode(tree) ? document() : fragment(), file);\\n\\n  if (stitches) {\\n    (0, _unistUtilVisit.visit)(result, 'comment', (node, index, parent) => {\\n      const stitch = node;\\n\\n      if (stitch.value.stitch && parent !== null && index !== null) {\\n        // @ts-expect-error: assume the stitch is allowed.\\n        parent.children[index] = stitch.value.stitch;\\n        return index;\\n      }\\n    });\\n  } // Unpack if possible and when not given a `root`.\\n\\n\\n  if (tree.type !== 'root' && result.type === 'root' && result.children.length === 1) {\\n    return result.children[0];\\n  }\\n\\n  return result;\\n  /**\\n   * @returns {P5Fragment}\\n   */\\n\\n  function fragment() {\\n    /** @type {P5Element} */\\n    const context = {\\n      nodeName: 'template',\\n      tagName: 'template',\\n      attrs: [],\\n      namespaceURI: _webNamespaces.webNamespaces.html,\\n      childNodes: []\\n    };\\n    /** @type {P5Element} */\\n\\n    const mock = {\\n      nodeName: 'documentmock',\\n      tagName: 'documentmock',\\n      attrs: [],\\n      namespaceURI: _webNamespaces.webNamespaces.html,\\n      childNodes: []\\n    };\\n    /** @type {P5Fragment} */\\n\\n    const doc = {\\n      nodeName: '#document-fragment',\\n      childNodes: []\\n    };\\n\\n    parser._bootstrap(mock, context);\\n\\n    parser._pushTmplInsertionMode(inTemplateMode);\\n\\n    parser._initTokenizerForFragmentParsing();\\n\\n    parser._insertFakeRootElement();\\n\\n    parser._resetInsertionMode();\\n\\n    parser._findFormInFragmentContext();\\n\\n    tokenizer = parser.tokenizer;\\n    /* c8 ignore next */\\n\\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\\n    preprocessor = tokenizer.preprocessor;\\n    locationTracker = tokenizer.__mixins[0];\\n    posTracker = locationTracker.posTracker;\\n    one(tree);\\n    resetTokenizer();\\n\\n    parser._adoptNodes(mock.childNodes[0], doc);\\n\\n    return doc;\\n  }\\n  /**\\n   * @returns {P5Document}\\n   */\\n\\n\\n  function document() {\\n    /** @type {P5Document} */\\n    const doc = parser.treeAdapter.createDocument();\\n\\n    parser._bootstrap(doc, undefined);\\n\\n    tokenizer = parser.tokenizer;\\n    /* c8 ignore next */\\n\\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\\n    preprocessor = tokenizer.preprocessor;\\n    locationTracker = tokenizer.__mixins[0];\\n    posTracker = locationTracker.posTracker;\\n    one(tree);\\n    resetTokenizer();\\n    return doc;\\n  }\\n  /**\\n   * @param {Array<Content>} nodes\\n   * @returns {void}\\n   */\\n\\n\\n  function all(nodes) {\\n    let index = -1;\\n    /* istanbul ignore else - invalid nodes, see rehypejs/rehype-raw#7. */\\n\\n    if (nodes) {\\n      while (++index < nodes.length) {\\n        one(nodes[index]);\\n      }\\n    }\\n  }\\n  /**\\n   * @param {Root} node\\n   * @returns {void}\\n   */\\n\\n\\n  function root(node) {\\n    all(node.children);\\n  }\\n  /**\\n   * @param {Element} node\\n   * @returns {void}\\n   */\\n\\n\\n  function element(node) {\\n    resetTokenizer();\\n\\n    parser._processInputToken(startTag(node));\\n\\n    all(node.children);\\n\\n    if (!_htmlVoidElements.htmlVoidElements.includes(node.tagName)) {\\n      resetTokenizer();\\n\\n      parser._processInputToken(endTag(node));\\n    }\\n  }\\n  /**\\n   * @param {Text} node\\n   * @returns {void}\\n   */\\n\\n\\n  function text(node) {\\n    resetTokenizer();\\n\\n    parser._processInputToken({\\n      type: characterToken,\\n      chars: node.value,\\n      location: createParse5Location(node)\\n    });\\n  }\\n  /**\\n   * @param {Doctype} node\\n   * @returns {void}\\n   */\\n\\n\\n  function doctype(node) {\\n    resetTokenizer();\\n\\n    parser._processInputToken({\\n      type: doctypeToken,\\n      name: 'html',\\n      forceQuirks: false,\\n      publicId: '',\\n      systemId: '',\\n      location: createParse5Location(node)\\n    });\\n  }\\n  /**\\n   * @param {Comment|Stitch} node\\n   * @returns {void}\\n   */\\n\\n\\n  function comment(node) {\\n    resetTokenizer();\\n\\n    parser._processInputToken({\\n      type: commentToken,\\n      data: node.value,\\n      location: createParse5Location(node)\\n    });\\n  }\\n  /**\\n   * @param {Raw} node\\n   * @returns {void}\\n   */\\n\\n\\n  function handleRaw(node) {\\n    const start = (0, _unistUtilPosition.pointStart)(node);\\n    const line = start.line || 1;\\n    const column = start.column || 1;\\n    const offset = start.offset || 0;\\n    /* c8 ignore next 4 */\\n\\n    if (!preprocessor) throw new Error('Expected `preprocessor`');\\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\\n    if (!posTracker) throw new Error('Expected `posTracker`');\\n    if (!locationTracker) throw new Error('Expected `locationTracker`'); // Reset preprocessor:\\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/tokenizer/preprocessor.js#L17>.\\n\\n    preprocessor.html = undefined;\\n    preprocessor.pos = -1;\\n    preprocessor.lastGapPos = -1;\\n    preprocessor.lastCharPos = -1;\\n    preprocessor.gapStack = [];\\n    preprocessor.skipNextNewLine = false;\\n    preprocessor.lastChunkWritten = false;\\n    preprocessor.endOfChunkHit = false; // Reset preprocessor mixin:\\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/extensions/position-tracking/preprocessor-mixin.js>.\\n\\n    posTracker.isEol = false;\\n    posTracker.lineStartPos = -column + 1; // Looks weird, but ensures we get correct positional info.\\n\\n    posTracker.droppedBufferSize = offset;\\n    posTracker.offset = 0;\\n    posTracker.col = 1;\\n    posTracker.line = line; // Reset location tracker:\\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/extensions/location-info/tokenizer-mixin.js>.\\n\\n    locationTracker.currentAttrLocation = undefined;\\n    locationTracker.ctLoc = createParse5Location(node); // See the code for `parse` and `parseFragment`:\\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/parser/index.js#L371>.\\n\\n    tokenizer.write(node.value);\\n\\n    parser._runParsingLoop(null); // Character references hang, so if we ended there, we need to flush\\n    // those too.\\n    // We reset the preprocessor as if the document ends here.\\n    // Then one single call to the relevant state does the trick, parse5\\n    // consumes the whole token.\\n\\n\\n    if (tokenizer.state === 'NAMED_CHARACTER_REFERENCE_STATE' || tokenizer.state === 'NUMERIC_CHARACTER_REFERENCE_END_STATE') {\\n      preprocessor.lastChunkWritten = true;\\n      tokenizer[tokenizer.state](tokenizer._consume());\\n    }\\n  }\\n  /**\\n   * @param {Node} node\\n   */\\n\\n\\n  function stitch(node) {\\n    stitches = true;\\n    /** @type {Node} */\\n\\n    let clone; // Recurse, because to somewhat handle `[<x>]</x>` (where `[]` denotes the\\n    // passed through node).\\n\\n    if ('children' in node) {\\n      clone = { ...node,\\n        children: raw({\\n          type: 'root',\\n          children: node.children\\n        }, file, options // @ts-expect-error Assume a given parent yields a parent.\\n        ).children\\n      };\\n    } else {\\n      clone = { ...node\\n      };\\n    } // Hack: `value` is supposed to be a string, but as none of the tools\\n    // (`parse5` or `hast-util-from-parse5`) looks at it, we can pass nodes\\n    // through.\\n\\n\\n    comment({\\n      type: 'comment',\\n      value: {\\n        stitch: clone\\n      }\\n    });\\n  }\\n\\n  function resetTokenizer() {\\n    /* c8 ignore next 2 */\\n    if (!tokenizer) throw new Error('Expected `tokenizer`');\\n    if (!posTracker) throw new Error('Expected `posTracker`'); // Process final characters if they\\u2019re still there after hibernating.\\n    // Similar to:\\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/extensions/location-info/tokenizer-mixin.js#L95>.\\n\\n    const token = tokenizer.currentCharacterToken;\\n\\n    if (token) {\\n      token.location.endLine = posTracker.line;\\n      token.location.endCol = posTracker.col + 1;\\n      token.location.endOffset = posTracker.offset + 1;\\n\\n      parser._processInputToken(token);\\n    } // Reset tokenizer:\\n    // See: <https://github.com/inikulin/parse5/blob/9c683e1/packages/parse5/lib/tokenizer/index.js#L218-L234>.\\n    // Especially putting it back in the `data` state is useful: some elements,\\n    // like textareas and iframes, change the state.\\n    // See GH-7.\\n    // But also if broken HTML is in `raw`, and then a correct element is given.\\n    // See GH-11.\\n\\n\\n    tokenizer.tokenQueue = [];\\n    tokenizer.state = dataState;\\n    tokenizer.returnState = '';\\n    tokenizer.charRefCode = -1;\\n    tokenizer.tempBuff = [];\\n    tokenizer.lastStartTagName = '';\\n    tokenizer.consumedAfterSnapshot = -1;\\n    tokenizer.active = false;\\n    tokenizer.currentCharacterToken = undefined;\\n    tokenizer.currentToken = undefined;\\n    tokenizer.currentAttr = undefined;\\n  }\\n};\\n/**\\n * @param {Element} node\\n * @returns {HiddenToken}\\n */\\n\\n\\nexports.raw = raw;\\n\\nfunction startTag(node) {\\n  /** @type {P5Location} */\\n  const location = Object.assign(createParse5Location(node)); // @ts-expect-error extra positional info.\\n\\n  location.startTag = Object.assign({}, location); // Untyped token.\\n\\n  return {\\n    type: startTagToken,\\n    tagName: node.tagName,\\n    selfClosing: false,\\n    attrs: attributes(node),\\n    location\\n  };\\n}\\n/**\\n * @param {Element} node\\n * @returns {Array<P5Attribute>}\\n */\\n\\n\\nfunction attributes(node) {\\n  return (0, _hastUtilToParse.toParse5)({\\n    tagName: node.tagName,\\n    type: 'element',\\n    properties: node.properties,\\n    children: [] // @ts-expect-error Assume element.\\n\\n  }).attrs;\\n}\\n/**\\n * @param {Element} node\\n * @returns {HiddenToken}\\n */\\n\\n\\nfunction endTag(node) {\\n  /** @type {P5Location} */\\n  const location = Object.assign(createParse5Location(node)); // @ts-expect-error extra positional info.\\n\\n  location.startTag = Object.assign({}, location); // Untyped token.\\n\\n  return {\\n    type: endTagToken,\\n    tagName: node.tagName,\\n    attrs: [],\\n    location\\n  };\\n}\\n/**\\n * @param {Node} node\\n */\\n\\n\\nfunction unknown(node) {\\n  throw new Error('Cannot compile `' + node.type + '` node');\\n}\\n/**\\n * @param {Node} node\\n * @returns {boolean}\\n */\\n\\n\\nfunction documentMode(node) {\\n  const head = node.type === 'root' ? node.children[0] : node;\\n  return Boolean(head && (head.type === 'doctype' || head.type === 'element' && head.tagName === 'html'));\\n}\\n/**\\n * @param {Node|Stitch} node\\n * @returns {P5Location}\\n */\\n\\n\\nfunction createParse5Location(node) {\\n  const start = (0, _unistUtilPosition.pointStart)(node);\\n  const end = (0, _unistUtilPosition.pointEnd)(node);\\n  return {\\n    startLine: start.line,\\n    startCol: start.column,\\n    startOffset: start.offset,\\n    endLine: end.line,\\n    endCol: end.column,\\n    endOffset: end.offset\\n  };\\n}\\n/**\\n * @param {VFile|Options|undefined} value\\n * @return {value is Options}\\n */\\n\\n\\nfunction isOptions(value) {\\n  return Boolean(value && !('message' in value && 'messages' in value));\\n}\\n};\"],\n\"names\":[\"shadow$provide\",\"global\",\"require\",\"module\",\"exports\",\"unknown\",\"node\",\"Error\",\"type\",\"documentMode\",\"head\",\"children\",\"tagName\",\"createParse5Location\",\"start\",\"_unistUtilPosition\",\"pointStart\",\"end\",\"pointEnd\",\"startLine\",\"line\",\"startCol\",\"column\",\"startOffset\",\"offset\",\"endLine\",\"endCol\",\"endOffset\",\"Object\",\"defineProperty\",\"value\",\"raw\",\"_index\",\"_interopRequireDefault\",\"obj\",\"__esModule\",\"default\",\"_unistUtilVisit\",\"_hastUtilFromParse\",\"_hastUtilToParse\",\"_htmlVoidElements\",\"_webNamespaces\",\"_zwitch\",\"parseOptions\",\"sourceCodeLocationInfo\",\"scriptingEnabled\",\"tree\",\"file\",\"options\",\"fragment\",\"mock\",\"nodeName\",\"attrs\",\"namespaceURI\",\"webNamespaces\",\"html\",\"childNodes\",\"doc\",\"parser\",\"_bootstrap\",\"context\",\"_pushTmplInsertionMode\",\"inTemplateMode\",\"_initTokenizerForFragmentParsing\",\"_insertFakeRootElement\",\"_resetInsertionMode\",\"_findFormInFragmentContext\",\"tokenizer\",\"preprocessor\",\"locationTracker\",\"__mixins\",\"posTracker\",\"one\",\"resetTokenizer\",\"_adoptNodes\",\"document\",\"treeAdapter\",\"createDocument\",\"undefined\",\"all\",\"nodes\",\"index\",\"length\",\"comment\",\"_processInputToken\",\"commentToken\",\"data\",\"location\",\"stitch\",\"stitches\",\"clone\",\"token\",\"currentCharacterToken\",\"col\",\"tokenQueue\",\"state\",\"dataState\",\"returnState\",\"charRefCode\",\"tempBuff\",\"lastStartTagName\",\"consumedAfterSnapshot\",\"active\",\"currentToken\",\"currentAttr\",\"zwitch\",\"handlers\",\"root\",\"element\",\"assign\",\"startTag\",\"startTagToken\",\"selfClosing\",\"toParse5\",\"properties\",\"htmlVoidElements\",\"includes\",\"endTagToken\",\"text\",\"characterToken\",\"chars\",\"doctype\",\"doctypeToken\",\"name\",\"forceQuirks\",\"publicId\",\"systemId\",\"handleRaw\",\"pos\",\"lastGapPos\",\"lastCharPos\",\"gapStack\",\"skipNextNewLine\",\"lastChunkWritten\",\"endOfChunkHit\",\"isEol\",\"lineStartPos\",\"droppedBufferSize\",\"currentAttrLocation\",\"ctLoc\",\"write\",\"_runParsingLoop\",\"_consume\",\"passThrough\",\"result\",\"fromParse5\",\"visit\",\"parent\"]\n}\n"]