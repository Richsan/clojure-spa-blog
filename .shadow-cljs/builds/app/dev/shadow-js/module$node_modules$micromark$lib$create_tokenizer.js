["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/micromark/lib/create-tokenizer.js"],"~:js","shadow$provide.module$node_modules$micromark$lib$create_tokenizer=function(global,require,module,exports){Object.defineProperty(exports,\"__esModule\",{value:!0});exports.createTokenizer=function(parser,initialize,from){function sliceStream(token){var chunks=chunks$jscomp$0,startIndex=token.start._index;const startBufferIndex=token.start._bufferIndex,endIndex=token.end._index;token=token.end._bufferIndex;startIndex===endIndex?startIndex=[chunks[startIndex].slice(startBufferIndex,token)]:(startIndex=\nchunks.slice(startIndex,endIndex),-1<startBufferIndex&&(startIndex[0]=startIndex[0].slice(startBufferIndex)),0<token&&startIndex.push(chunks[endIndex].slice(0,token)));return startIndex}function now(){return Object.assign({},point)}function onsuccessfulcheck(_,info){info.restore()}function constructFactory(onreturn,fields){return function(constructs,returnState,bogusState){function handleMapOfConstructs(map){return function(code){var def=null!==code&&map[code];const all=null!==code&&map.null;def=\n[...(Array.isArray(def)?def:def?[def]:[]),...(Array.isArray(all)?all:all?[all]:[])];return handleListOfConstructs(def)(code)}}function handleListOfConstructs(list){listOfConstructs=list;constructIndex=0;return 0===list.length?bogusState:handleConstruct(list[constructIndex])}function handleConstruct(construct){return function(code){info=store();currentConstruct=construct;construct.partial||(context.currentConstruct=construct);return construct.name&&context.parser.constructs.disable.null.includes(construct.name)?\nnok(code):construct.tokenize.call(fields?Object.assign(Object.create(context),fields):context,effects,ok,nok)(code)}}function ok(code){onreturn(currentConstruct,info);return returnState}function nok(code){info.restore();return++constructIndex<listOfConstructs.length?handleConstruct(listOfConstructs[constructIndex]):bogusState}let listOfConstructs,constructIndex,currentConstruct,info;return Array.isArray(constructs)?handleListOfConstructs(constructs):\"tokenize\"in constructs?handleListOfConstructs([constructs]):\nhandleMapOfConstructs(constructs)}}function addResult(construct,from){construct.resolveAll&&!resolveAllConstructs.includes(construct)&&resolveAllConstructs.push(construct);construct.resolve&&(0,_micromarkUtilChunked.splice)(context.events,from,context.events.length-from,construct.resolve(context.events.slice(from),context));construct.resolveTo&&(context.events=construct.resolveTo(context.events,context))}function store(){const startPoint=now(),startPrevious=context.previous,startCurrentConstruct=\ncontext.currentConstruct,startEventsIndex=context.events.length,startStack=Array.from(stack);return{restore:function(){point=startPoint;context.previous=startPrevious;context.currentConstruct=startCurrentConstruct;context.events.length=startEventsIndex;stack=startStack;accountForPotentialSkip()},from:startEventsIndex}}function accountForPotentialSkip(){point.line in columnStart&&2>point.column&&(point.column=columnStart[point.line],point.offset+=columnStart[point.line]-1)}let point=Object.assign(from?\nObject.assign({},from):{line:1,column:1,offset:0},{_index:0,_bufferIndex:-1});const columnStart={},resolveAllConstructs=[];let chunks$jscomp$0=[],stack=[];const effects={consume:function(code){(0,_micromarkUtilCharacter.markdownLineEnding)(code)?(point.line++,point.column=1,point.offset+=-3===code?2:1,accountForPotentialSkip()):-1!==code&&(point.column++,point.offset++);0>point._bufferIndex?point._index++:(point._bufferIndex++,point._bufferIndex===chunks$jscomp$0[point._index].length&&(point._bufferIndex=\n-1,point._index++));context.previous=code},enter:function(type,fields){fields=fields||{};fields.type=type;fields.start=now();context.events.push([\"enter\",fields,context]);stack.push(fields);return fields},exit:function(type){type=stack.pop();type.end=now();context.events.push([\"exit\",type,context]);return type},attempt:constructFactory(function(construct,info){addResult(construct,info.from)}),check:constructFactory(onsuccessfulcheck),interrupt:constructFactory(onsuccessfulcheck,{interrupt:!0})},context=\n{previous:null,code:null,containerState:{},events:[],parser,sliceStream,sliceSerialize:function(token,expandTabs){token=sliceStream(token);let index=-1;const result=[];let atTab;for(;++index<token.length;){const chunk=token[index];let value;if(\"string\"===typeof chunk)value=chunk;else switch(chunk){case -5:value=\"\\r\";break;case -4:value=\"\\n\";break;case -3:value=\"\\r\\n\";break;case -2:value=expandTabs?\" \":\"\\t\";break;case -1:if(!expandTabs&&atTab)continue;value=\" \";break;default:value=String.fromCharCode(chunk)}atTab=\n-2===chunk;result.push(value)}return result.join(\"\")},now,defineSkip:function(value){columnStart[value.line]=value.column;accountForPotentialSkip()},write:function(slice){for(chunks$jscomp$0=(0,_micromarkUtilChunked.push)(chunks$jscomp$0,slice);point._index<chunks$jscomp$0.length;){const chunk=chunks$jscomp$0[point._index];if(\"string\"===typeof chunk)for(slice=point._index,0>point._bufferIndex&&(point._bufferIndex=0);point._index===slice&&point._bufferIndex<chunk.length;)state=state(chunk.charCodeAt(point._bufferIndex));\nelse state=state(chunk)}if(null!==chunks$jscomp$0[chunks$jscomp$0.length-1])return[];addResult(initialize,0);context.events=(0,_micromarkUtilResolveAll.resolveAll)(resolveAllConstructs,context.events,context);return context.events}};let state=initialize.tokenize.call(context,effects);initialize.resolveAll&&resolveAllConstructs.push(initialize);return context};var _micromarkUtilCharacter=require(\"module$node_modules$micromark_util_character$index\"),_micromarkUtilChunked=require(\"module$node_modules$micromark_util_chunked$index\"),\n_micromarkUtilResolveAll=require(\"module$node_modules$micromark_util_resolve_all$index\")}","~:source","shadow$provide[\"module$node_modules$micromark$lib$create_tokenizer\"] = function(global,require,module,exports) {\n\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.createTokenizer = createTokenizer;\n\nvar _micromarkUtilCharacter = require(\"micromark-util-character\");\n\nvar _micromarkUtilChunked = require(\"micromark-util-chunked\");\n\nvar _micromarkUtilResolveAll = require(\"micromark-util-resolve-all\");\n\n/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n */\n\n/**\n * @typedef Info\n * @property {() => void} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\n\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_index'|'_bufferIndex'>} [from]\n * @returns {TokenizeContext}\n */\nfunction createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(from ? Object.assign({}, from) : {\n    line: 1,\n    column: 1,\n    offset: 0\n  }, {\n    _index: 0,\n    _bufferIndex: -1\n  });\n  /** @type {Record<string, number>} */\n\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n\n  let chunks = [];\n  /** @type {Array<Token>} */\n\n  let stack = [];\n  /** @type {boolean|undefined} */\n\n  let consumed = true;\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  };\n  /**\n   * The state function.\n   *\n   * @type {State|void}\n   */\n\n  let state = initialize.tokenize.call(context, effects);\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n\n  let expectedCode;\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n\n  return context;\n  /** @type {TokenizeContext['write']} */\n\n  function write(slice) {\n    chunks = (0, _micromarkUtilChunked.push)(chunks, slice);\n    main(); // Exit if we’re not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n\n    addResult(initialize, 0); // Otherwise, resolve, and exit.\n\n    context.events = (0, _micromarkUtilResolveAll.resolveAll)(resolveAllConstructs, context.events, context);\n    return context.events;\n  } //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n\n\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n  /** @type {TokenizeContext['sliceStream']} */\n\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n  /** @type {TokenizeContext['now']} */\n\n\n  function now() {\n    return Object.assign({}, point);\n  }\n  /** @type {TokenizeContext['defineSkip']} */\n\n\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  } //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n\n\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]; // If we’re in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n\n\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n  /** @type {Effects['consume']} */\n\n\n  function consume(code) {\n    if ((0, _micromarkUtilCharacter.markdownLineEnding)(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    } // Not in a string chunk.\n\n\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++; // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    } // Expose the previous character.\n\n\n    context.previous = code; // Mark as consumed.\n\n    consumed = true;\n  }\n  /** @type {Effects['enter']} */\n\n\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n  /** @type {Effects['exit']} */\n\n\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n\n\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {Record<string, unknown>} [fields]\n   */\n\n\n  function constructFactory(onreturn, fields) {\n    return hook;\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Construct|Array<Construct>|ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State} [bogusState]\n     * @returns {State}\n     */\n\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n\n      let constructIndex;\n      /** @type {Construct} */\n\n      let currentConstruct;\n      /** @type {Info} */\n\n      let info;\n      return Array.isArray(constructs) ?\n      /* c8 ignore next 1 */\n      handleListOfConstructs(constructs) : 'tokenize' in constructs // @ts-expect-error Looks like a construct.\n      ? handleListOfConstructs([constructs]) : handleMapOfConstructs(constructs);\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n\n      function handleMapOfConstructs(map) {\n        return start;\n        /** @type {State} */\n\n        function start(code) {\n          const def = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [// To do: add more extension tests.\n\n          /* c8 ignore next 2 */\n          ...(Array.isArray(def) ? def : def ? [def] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n\n        if (list.length === 0) {\n          return bogusState;\n        }\n\n        return handleConstruct(list[constructIndex]);\n      }\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n\n\n      function handleConstruct(construct) {\n        return start;\n        /** @type {State} */\n\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n\n          return construct.tokenize.call( // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a “live binding”, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n      /** @type {State} */\n\n\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n      /** @type {State} */\n\n\n      function nok(code) {\n        consumed = true;\n        info.restore();\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n\n        return bogusState;\n      }\n    }\n  }\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n\n    if (construct.resolve) {\n      (0, _micromarkUtilChunked.splice)(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n\n\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      restore,\n      from: startEventsIndex\n    };\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'start'|'end'>} token\n * @returns {Array<Chunk>}\n */\n\n\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n\n  let view;\n\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n\n    if (startBufferIndex > -1) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view[0] = view[0].slice(startBufferIndex);\n    }\n\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n\n  return view;\n}\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean} [expandTabs=false]\n * @returns {string}\n */\n\n\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n\n  const result = [];\n  /** @type {boolean|undefined} */\n\n  let atTab;\n\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n\n    let value;\n\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = '\\r';\n          break;\n        }\n\n      case -4:\n        {\n          value = '\\n';\n          break;\n        }\n\n      case -3:\n        {\n          value = '\\r' + '\\n';\n          break;\n        }\n\n      case -2:\n        {\n          value = expandTabs ? ' ' : '\\t';\n          break;\n        }\n\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = ' ';\n          break;\n        }\n\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n\n    atTab = chunk === -2;\n    result.push(value);\n  }\n\n  return result.join('');\n}\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$module$node_modules$micromark_util_character$index","~$module$node_modules$micromark_util_resolve_all$index","~$shadow.js","~$module$node_modules$micromark_util_chunked$index"]],"~:properties",["^5",["consume","createTokenizer","parser","offset","__esModule","value","check","previous","start","sliceSerialize","sliceStream","length","events","line","column","attempt","interrupt","type","_bufferIndex","defineSkip","from","exit","now","currentConstruct","restore","_index","write","enter","code","containerState","end"]],"~:compiled-at",1676665867301,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$micromark$lib$create_tokenizer.js\",\n\"lineCount\":12,\n\"mappings\":\"AAAAA,cAAA,CAAA,kDAAA,CAAuE,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAG/GC,MAAOC,CAAAA,cAAP,CAAsBF,OAAtB,CAA+B,YAA/B,CAA6C,CAC3CG,MAAO,CAAA,CADoC,CAA7C,CAGAH,QAAQI,CAAAA,eAAR,CAgDAA,QAAwB,CAACC,MAAD,CAASC,UAAT,CAAqBC,IAArB,CAA2B,CA0GjDC,QAASA,YAAW,CAACC,KAAD,CAAQ,CACPC,IAAAA,OAAAA,eAAAA,CA6VfC,WA7VuBF,KA6VJG,CAAAA,KAAMC,CAAAA,MAC/B,OAAMC,iBA9VuBL,KA8VEG,CAAAA,KAAMG,CAAAA,YAArC,CACMC,SA/VuBP,KA+VNQ,CAAAA,GAAIJ,CAAAA,MACrBK,MAAAA,CAhWuBT,KAgWAQ,CAAAA,GAAIF,CAAAA,YAK7BJ,WAAJ,GAAmBK,QAAnB,CAEEG,UAFF,CAES,CAACT,MAAA,CAAOC,UAAP,CAAmBS,CAAAA,KAAnB,CAAyBN,gBAAzB,CAA2CI,KAA3C,CAAD,CAFT,EAIEC,UAOA;AAPOT,MAAOU,CAAAA,KAAP,CAAaT,UAAb,CAAyBK,QAAzB,CAOP,CALuB,CAAC,CAKxB,CALIF,gBAKJ,GAHEK,UAAA,CAAK,CAAL,CAGF,CAHYA,UAAA,CAAK,CAAL,CAAQC,CAAAA,KAAR,CAAcN,gBAAd,CAGZ,EAAqB,CAArB,CAAII,KAAJ,EAEEC,UAAKE,CAAAA,IAAL,CAAUX,MAAA,CAAOM,QAAP,CAAiBI,CAAAA,KAAjB,CAAuB,CAAvB,CAA0BF,KAA1B,CAAV,CAbJ,CArWE,OAsXKC,WAvXqB,CAM5BG,QAASA,IAAG,EAAG,CACb,MAAOrB,OAAOsB,CAAAA,MAAP,CAAc,EAAd,CAAkBC,KAAlB,CADM,CAoIfC,QAASA,kBAAiB,CAACC,CAAD,CAAIC,IAAJ,CAAU,CAClCA,IAAKC,CAAAA,OAAL,EADkC,CAWpCC,QAASA,iBAAgB,CAACC,QAAD,CAAWC,MAAX,CAAmB,CAC1C,MAWAC,SAAa,CAACC,UAAD,CAAaC,WAAb,CAA0BC,UAA1B,CAAsC,CAuBjDC,QAASA,sBAAqB,CAACC,GAAD,CAAM,CAClC,MAGAzB,SAAc,CAAC0B,IAAD,CAAO,CACnB,IAAMC,IAAe,IAAfA,GAAMD,IAANC,EAAuBF,GAAA,CAAIC,IAAJ,CAC7B,OAAME,IAAe,IAAfA,GAAMF,IAANE,EAAuBH,GAAII,CAAAA,IAC3BC,IAAAA;AAAO,CAGb,IAAIC,KAAMC,CAAAA,OAAN,CAAcL,GAAd,CAAA,CAAqBA,GAArB,CAA2BA,GAAA,CAAM,CAACA,GAAD,CAAN,CAAc,EAA7C,CAHa,CAGqC,IAAII,KAAMC,CAAAA,OAAN,CAAcJ,GAAd,CAAA,CAAqBA,GAArB,CAA2BA,GAAA,CAAM,CAACA,GAAD,CAAN,CAAc,EAA7C,CAHrC,CAIb,OAAOK,uBAAA,CAAuBH,GAAvB,CAAA,CAA6BJ,IAA7B,CAPY,CAJa,CAsBpCO,QAASA,uBAAsB,CAACH,IAAD,CAAO,CACpCI,gBAAA,CAAmBJ,IACnBK,eAAA,CAAiB,CAEjB,OAAoB,EAApB,GAAIL,IAAKM,CAAAA,MAAT,CACSb,UADT,CAIOc,eAAA,CAAgBP,IAAA,CAAKK,cAAL,CAAhB,CAR6B,CAkBtCE,QAASA,gBAAe,CAACC,SAAD,CAAY,CAClC,MAGAtC,SAAc,CAAC0B,IAAD,CAAO,CAKnBX,IAAA,CAAOwB,KAAA,EACPC,iBAAA,CAAmBF,SAEdA,UAAUG,CAAAA,OAAf,GACEC,OAAQF,CAAAA,gBADV,CAC6BF,SAD7B,CAIA,OAAIA,UAAUK,CAAAA,IAAd,EAAsBD,OAAQjD,CAAAA,MAAO4B,CAAAA,UAAWuB,CAAAA,OAAQf,CAAAA,IAAKgB,CAAAA,QAAvC,CAAgDP,SAAUK,CAAAA,IAA1D,CAAtB;AACSG,GAAA,CAAIpB,IAAJ,CADT,CAIOY,SAAUS,CAAAA,QAASC,CAAAA,IAAnB,CAGP7B,MAAA,CAAS9B,MAAOsB,CAAAA,MAAP,CAActB,MAAO4D,CAAAA,MAAP,CAAcP,OAAd,CAAd,CAAsCvB,MAAtC,CAAT,CAAyDuB,OAHlD,CAG2DQ,OAH3D,CAGoEC,EAHpE,CAGwEL,GAHxE,CAAA,CAG6EpB,IAH7E,CAhBY,CAJa,CA6BpCyB,QAASA,GAAE,CAACzB,IAAD,CAAO,CAEhBR,QAAA,CAASsB,gBAAT,CAA2BzB,IAA3B,CACA,OAAOO,YAHS,CAQlBwB,QAASA,IAAG,CAACpB,IAAD,CAAO,CAEjBX,IAAKC,CAAAA,OAAL,EAEA,OAAI,EAAEmB,cAAN,CAAuBD,gBAAiBE,CAAAA,MAAxC,CACSC,eAAA,CAAgBH,gBAAA,CAAiBC,cAAjB,CAAhB,CADT,CAIOZ,UARU,CAlGnB,IAAIW,gBAAJ,CAGIC,cAHJ,CAMIK,gBANJ,CASIzB,IACJ,OAAOgB,MAAMC,CAAAA,OAAN,CAAcX,UAAd,CAAA,CAEPY,sBAAA,CAAuBZ,UAAvB,CAFO,CAE8B,UAAA,EAAcA,WAAd,CACnCY,sBAAA,CAAuB,CAACZ,UAAD,CAAvB,CADmC;AACIG,qBAAA,CAAsBH,UAAtB,CAfQ,CAZT,CAmI5C+B,QAASA,UAAS,CAACd,SAAD,CAAY3C,IAAZ,CAAkB,CAC9B2C,SAAUe,CAAAA,UAAd,EAA4B,CAACC,oBAAqBT,CAAAA,QAArB,CAA8BP,SAA9B,CAA7B,EACEgB,oBAAqB7C,CAAAA,IAArB,CAA0B6B,SAA1B,CAGEA,UAAUiB,CAAAA,OAAd,EACE,GAAIC,qBAAsBC,CAAAA,MAA1B,EAAkCf,OAAQgB,CAAAA,MAA1C,CAAkD/D,IAAlD,CAAwD+C,OAAQgB,CAAAA,MAAOtB,CAAAA,MAAvE,CAAgFzC,IAAhF,CAAsF2C,SAAUiB,CAAAA,OAAV,CAAkBb,OAAQgB,CAAAA,MAAOlD,CAAAA,KAAf,CAAqBb,IAArB,CAAlB,CAA8C+C,OAA9C,CAAtF,CAGEJ,UAAUqB,CAAAA,SAAd,GACEjB,OAAQgB,CAAAA,MADV,CACmBpB,SAAUqB,CAAAA,SAAV,CAAoBjB,OAAQgB,CAAAA,MAA5B,CAAoChB,OAApC,CADnB,CATkC,CAoBpCH,QAASA,MAAK,EAAG,CACf,MAAMqB,WAAalD,GAAA,EAAnB,CACMmD,cAAgBnB,OAAQoB,CAAAA,QAD9B,CAEMC;AAAwBrB,OAAQF,CAAAA,gBAFtC,CAGMwB,iBAAmBtB,OAAQgB,CAAAA,MAAOtB,CAAAA,MAHxC,CAIM6B,WAAalC,KAAMpC,CAAAA,IAAN,CAAWuE,KAAX,CACnB,OAAO,CACLlD,QASFA,QAAgB,EAAG,CACjBJ,KAAA,CAAQgD,UACRlB,QAAQoB,CAAAA,QAAR,CAAmBD,aACnBnB,QAAQF,CAAAA,gBAAR,CAA2BuB,qBAC3BrB,QAAQgB,CAAAA,MAAOtB,CAAAA,MAAf,CAAwB4B,gBACxBE,MAAA,CAAQD,UACRE,wBAAA,EANiB,CAVZ,CAELxE,KAAMqE,gBAFD,CANQ,CAiCjBG,QAASA,wBAAuB,EAAG,CAC7BvD,KAAMwD,CAAAA,IAAV,GAAkBC,YAAlB,EAAgD,CAAhD,CAAiCzD,KAAM0D,CAAAA,MAAvC,GACE1D,KAAM0D,CAAAA,MACN,CADeD,WAAA,CAAYzD,KAAMwD,CAAAA,IAAlB,CACf,CAAAxD,KAAM2D,CAAAA,MAAN,EAAgBF,WAAA,CAAYzD,KAAMwD,CAAAA,IAAlB,CAAhB,CAA0C,CAF5C,CADiC,CArbnC,IAAIxD,MAAQvB,MAAOsB,CAAAA,MAAP,CAAchB,IAAA;AAAON,MAAOsB,CAAAA,MAAP,CAAc,EAAd,CAAkBhB,IAAlB,CAAP,CAAiC,CACzDyE,KAAM,CADmD,CAEzDE,OAAQ,CAFiD,CAGzDC,OAAQ,CAHiD,CAA/C,CAIT,CACDtE,OAAQ,CADP,CAEDE,aAAc,CAAC,CAFd,CAJS,CAUZ,OAAMkE,YAAc,EAApB,CAGMf,qBAAuB,EAG7B,KAAIxD,gBAAS,EAAb,CAGIoE,MAAQ,EAUZ,OAAMhB,QAAU,CACdsB,QA+IFA,QAAgB,CAAC9C,IAAD,CAAO,CACjB,GAAI+C,uBAAwBC,CAAAA,kBAA5B,EAAgDhD,IAAhD,CAAJ,EACEd,KAAMwD,CAAAA,IAAN,EAGA,CAFAxD,KAAM0D,CAAAA,MAEN,CAFe,CAEf,CADA1D,KAAM2D,CAAAA,MACN,EADyB,CAAC,CAAV,GAAA7C,IAAA,CAAc,CAAd,CAAkB,CAClC,CAAAyC,uBAAA,EAJF,EAKoB,CAAC,CALrB,GAKWzC,IALX,GAMEd,KAAM0D,CAAAA,MAAN,EACA,CAAA1D,KAAM2D,CAAAA,MAAN,EAPF,CAWyB,EAAzB,CAAI3D,KAAMT,CAAAA,YAAV,CACES,KAAMX,CAAAA,MAAN,EADF,EAGEW,KAAMT,CAAAA,YAAN,EAIA,CAAIS,KAAMT,CAAAA,YAAV,GAA2BL,eAAA,CAAOc,KAAMX,CAAAA,MAAb,CAAqBmC,CAAAA,MAAhD,GACExB,KAAMT,CAAAA,YACN;AADqB,CAAC,CACtB,CAAAS,KAAMX,CAAAA,MAAN,EAFF,CAPF,CAcAyC,QAAQoB,CAAAA,QAAR,CAAmBpC,IA1BE,CAhJP,CAEdiD,MA+KFA,QAAc,CAACC,IAAD,CAAOzD,MAAP,CAAe,CAGrBtB,MAAAA,CAAQsB,MAARtB,EAAkB,EACxBA,OAAM+E,CAAAA,IAAN,CAAaA,IACb/E,OAAMG,CAAAA,KAAN,CAAcU,GAAA,EACdgC,QAAQgB,CAAAA,MAAOjD,CAAAA,IAAf,CAAoB,CAAC,OAAD,CAAUZ,MAAV,CAAiB6C,OAAjB,CAApB,CACAwB,MAAMzD,CAAAA,IAAN,CAAWZ,MAAX,CACA,OAAOA,OARoB,CAjLb,CAGdgF,KA2LFA,QAAa,CAACD,IAAD,CAAO,CACZ/E,IAAAA,CAAQqE,KAAMY,CAAAA,GAAN,EACdjF,KAAMQ,CAAAA,GAAN,CAAYK,GAAA,EACZgC,QAAQgB,CAAAA,MAAOjD,CAAAA,IAAf,CAAoB,CAAC,MAAD,CAASZ,IAAT,CAAgB6C,OAAhB,CAApB,CACA,OAAO7C,KAJW,CA9LJ,CAIdkF,QAAS9D,gBAAA,CAuMX+D,QAA8B,CAAC1C,SAAD,CAAYvB,IAAZ,CAAkB,CAC9CqC,SAAA,CAAUd,SAAV,CAAqBvB,IAAKpB,CAAAA,IAA1B,CAD8C,CAvMrC,CAJK,CAKdsF,MAAOhE,gBAAA,CAAiBJ,iBAAjB,CALO,CAMdqE,UAAWjE,gBAAA,CAAiBJ,iBAAjB,CAAoC,CAC7CqE,UAAW,CAAA,CADkC,CAApC,CANG,CAAhB,CAgBMxC;AAAU,CACdoB,SAAU,IADI,CAEdpC,KAAM,IAFQ,CAGdyD,eAAgB,EAHF,CAIdzB,OAAQ,EAJM,CAKdjE,MALc,CAMdG,WANc,CAOdwF,eA8CFA,QAAuB,CAACvF,KAAD,CAAQwF,UAAR,CAAoB,CAClB,KAAA,CAAAzF,WAAA,CAAYC,KAAZ,CAwYzB,KAAIyF,MAAQ,CAAC,CAGb,OAAMC,OAAS,EAGf,KAAIC,KAEJ,KAAA,CAAO,EAAEF,KAAT,CAAiBxF,KAAOsC,CAAAA,MAAxB,CAAA,CAAgC,CAC9B,MAAMqD,MAAQ3F,KAAA,CAAOwF,KAAP,CAGd,KAAI/F,KAEJ,IAAqB,QAArB,GAAI,MAAOkG,MAAX,CACElG,KAAA,CAAQkG,KADV,KAEO,QAAQA,KAAR,EACL,KAAK,CAAC,CAAN,CAEIlG,KAAA,CAAQ,IACR,MAGJ,MAAK,CAAC,CAAN,CAEIA,KAAA,CAAQ,IACR,MAGJ,MAAK,CAAC,CAAN,CAEIA,KAAA,CAAQ,MACR,MAGJ,MAAK,CAAC,CAAN,CAEIA,KAAA,CA7aqC8F,UA6a7B,CAAa,GAAb,CAAmB,IAC3B,MAGJ,MAAK,CAAC,CAAN,CAEI,GAAI,CAnbiCA,UAmbrC,EAAmBG,KAAnB,CAA0B,QAC1BjG,MAAA,CAAQ,GACR,MAGJ,SAGIA,KAAA,CAAQmG,MAAOC,CAAAA,YAAP,CAAoBF,KAApB,CAnCP,CAuCPD,KAAA;AAAkB,CAAC,CAAnB,GAAQC,KACRF,OAAO9E,CAAAA,IAAP,CAAYlB,KAAZ,CAhD8B,CAhZ9B,MAmcKgG,OAAOK,CAAAA,IAAP,CAAY,EAAZ,CApcoC,CArD3B,CAQdlF,GARc,CASdmF,WA8DFA,QAAmB,CAACtG,KAAD,CAAQ,CACzB8E,WAAA,CAAY9E,KAAM6E,CAAAA,IAAlB,CAAA,CAA0B7E,KAAM+E,CAAAA,MAChCH,wBAAA,EAFyB,CAvEX,CAUd2B,MAwBFA,QAAc,CAACtF,KAAD,CAAQ,CA4DpB,IA3DAV,eA2DA,CA3DS,GAAI0D,qBAAsB/C,CAAAA,IAA1B,EAAgCX,eAAhC,CAAwCU,KAAxC,CA2DT,CAAOI,KAAMX,CAAAA,MAAb,CAAsBH,eAAOsC,CAAAA,MAA7B,CAAA,CAAqC,CACnC,MAAMqD,MAAQ3F,eAAA,CAAOc,KAAMX,CAAAA,MAAb,CAEd,IAAqB,QAArB,GAAI,MAAOwF,MAAX,CAOE,IANAM,KAEA,CAFanF,KAAMX,CAAAA,MAEnB,CAAyB,CAAzB,CAAIW,KAAMT,CAAAA,YAAV,GACES,KAAMT,CAAAA,YADR,CACuB,CADvB,CAIA,CAAOS,KAAMX,CAAAA,MAAb,GAAwB8F,KAAxB,EAAsCnF,KAAMT,CAAAA,YAA5C,CAA2DsF,KAAMrD,CAAAA,MAAjE,CAAA,CAmBJ4D,KAAA,CAAQA,KAAA,CAlBCP,KAAMQ,CAAAA,UAANvE,CAAiBd,KAAMT,CAAAA,YAAvBuB,CAkBD,CA1BN;IA0BFsE,MAAA,CAAQA,KAAA,CAfDP,KAeC,CA7B6B,CAxDrC,GAAkC,IAAlC,GAAI3F,eAAA,CAAOA,eAAOsC,CAAAA,MAAd,CAAuB,CAAvB,CAAJ,CACE,MAAO,EAGTgB,UAAA,CAAU1D,UAAV,CAAsB,CAAtB,CAEAgD,QAAQgB,CAAAA,MAAR,CAAiB,GAAIwC,wBAAyB7C,CAAAA,UAA7B,EAAyCC,oBAAzC,CAA+DZ,OAAQgB,CAAAA,MAAvE,CAA+EhB,OAA/E,CACjB,OAAOA,QAAQgB,CAAAA,MAXK,CAlCN,CAkBhB,KAAIsC,MAAQtG,UAAWqD,CAAAA,QAASC,CAAAA,IAApB,CAAyBN,OAAzB,CAAkCQ,OAAlC,CASRxD,WAAW2D,CAAAA,UAAf,EACEC,oBAAqB7C,CAAAA,IAArB,CAA0Bf,UAA1B,CAGF,OAAOgD,QA9E0C,CA9CnD,KAAI+B,wBAA0BvF,OAAA,CAAQ,oDAAR,CAA9B,CAEIsE,sBAAwBtE,OAAA,CAAQ,kDAAR,CAF5B;AAIIgH,yBAA2BhH,OAAA,CAAQ,sDAAR,CAZgF;\",\n\"sources\":[\"node_modules/micromark/lib/create-tokenizer.js\"],\n\"sourcesContent\":[\"shadow$provide[\\\"module$node_modules$micromark$lib$create_tokenizer\\\"] = function(global,require,module,exports) {\\n\\\"use strict\\\";\\n\\nObject.defineProperty(exports, \\\"__esModule\\\", {\\n  value: true\\n});\\nexports.createTokenizer = createTokenizer;\\n\\nvar _micromarkUtilCharacter = require(\\\"micromark-util-character\\\");\\n\\nvar _micromarkUtilChunked = require(\\\"micromark-util-chunked\\\");\\n\\nvar _micromarkUtilResolveAll = require(\\\"micromark-util-resolve-all\\\");\\n\\n/**\\n * @typedef {import('micromark-util-types').Code} Code\\n * @typedef {import('micromark-util-types').Chunk} Chunk\\n * @typedef {import('micromark-util-types').Point} Point\\n * @typedef {import('micromark-util-types').Token} Token\\n * @typedef {import('micromark-util-types').Effects} Effects\\n * @typedef {import('micromark-util-types').State} State\\n * @typedef {import('micromark-util-types').Construct} Construct\\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\\n */\\n\\n/**\\n * @typedef Info\\n * @property {() => void} restore\\n * @property {number} from\\n *\\n * @callback ReturnHandle\\n *   Handle a successful run.\\n * @param {Construct} construct\\n * @param {Info} info\\n * @returns {void}\\n */\\n\\n/**\\n * Create a tokenizer.\\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\\n * The parser is the object dealing with it all.\\n * `initialize` works like other constructs, except that only its `tokenize`\\n * function is used, in which case it doesn\\u2019t receive an `ok` or `nok`.\\n * `from` can be given to set the point before the first character, although\\n * when further lines are indented, they must be set with `defineSkip`.\\n *\\n * @param {ParseContext} parser\\n * @param {InitialConstruct} initialize\\n * @param {Omit<Point, '_index'|'_bufferIndex'>} [from]\\n * @returns {TokenizeContext}\\n */\\nfunction createTokenizer(parser, initialize, from) {\\n  /** @type {Point} */\\n  let point = Object.assign(from ? Object.assign({}, from) : {\\n    line: 1,\\n    column: 1,\\n    offset: 0\\n  }, {\\n    _index: 0,\\n    _bufferIndex: -1\\n  });\\n  /** @type {Record<string, number>} */\\n\\n  const columnStart = {};\\n  /** @type {Array<Construct>} */\\n\\n  const resolveAllConstructs = [];\\n  /** @type {Array<Chunk>} */\\n\\n  let chunks = [];\\n  /** @type {Array<Token>} */\\n\\n  let stack = [];\\n  /** @type {boolean|undefined} */\\n\\n  let consumed = true;\\n  /**\\n   * Tools used for tokenizing.\\n   *\\n   * @type {Effects}\\n   */\\n\\n  const effects = {\\n    consume,\\n    enter,\\n    exit,\\n    attempt: constructFactory(onsuccessfulconstruct),\\n    check: constructFactory(onsuccessfulcheck),\\n    interrupt: constructFactory(onsuccessfulcheck, {\\n      interrupt: true\\n    })\\n  };\\n  /**\\n   * State and tools for resolving and serializing.\\n   *\\n   * @type {TokenizeContext}\\n   */\\n\\n  const context = {\\n    previous: null,\\n    code: null,\\n    containerState: {},\\n    events: [],\\n    parser,\\n    sliceStream,\\n    sliceSerialize,\\n    now,\\n    defineSkip,\\n    write\\n  };\\n  /**\\n   * The state function.\\n   *\\n   * @type {State|void}\\n   */\\n\\n  let state = initialize.tokenize.call(context, effects);\\n  /**\\n   * Track which character we expect to be consumed, to catch bugs.\\n   *\\n   * @type {Code}\\n   */\\n\\n  let expectedCode;\\n\\n  if (initialize.resolveAll) {\\n    resolveAllConstructs.push(initialize);\\n  }\\n\\n  return context;\\n  /** @type {TokenizeContext['write']} */\\n\\n  function write(slice) {\\n    chunks = (0, _micromarkUtilChunked.push)(chunks, slice);\\n    main(); // Exit if we\\u2019re not done, resolve might change stuff.\\n\\n    if (chunks[chunks.length - 1] !== null) {\\n      return [];\\n    }\\n\\n    addResult(initialize, 0); // Otherwise, resolve, and exit.\\n\\n    context.events = (0, _micromarkUtilResolveAll.resolveAll)(resolveAllConstructs, context.events, context);\\n    return context.events;\\n  } //\\n  // Tools.\\n  //\\n\\n  /** @type {TokenizeContext['sliceSerialize']} */\\n\\n\\n  function sliceSerialize(token, expandTabs) {\\n    return serializeChunks(sliceStream(token), expandTabs);\\n  }\\n  /** @type {TokenizeContext['sliceStream']} */\\n\\n\\n  function sliceStream(token) {\\n    return sliceChunks(chunks, token);\\n  }\\n  /** @type {TokenizeContext['now']} */\\n\\n\\n  function now() {\\n    return Object.assign({}, point);\\n  }\\n  /** @type {TokenizeContext['defineSkip']} */\\n\\n\\n  function defineSkip(value) {\\n    columnStart[value.line] = value.column;\\n    accountForPotentialSkip();\\n  } //\\n  // State management.\\n  //\\n\\n  /**\\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\\n   * `consume`).\\n   * Here is where we walk through the chunks, which either include strings of\\n   * several characters, or numerical character codes.\\n   * The reason to do this in a loop instead of a call is so the stack can\\n   * drain.\\n   *\\n   * @returns {void}\\n   */\\n\\n\\n  function main() {\\n    /** @type {number} */\\n    let chunkIndex;\\n\\n    while (point._index < chunks.length) {\\n      const chunk = chunks[point._index]; // If we\\u2019re in a buffer chunk, loop through it.\\n\\n      if (typeof chunk === 'string') {\\n        chunkIndex = point._index;\\n\\n        if (point._bufferIndex < 0) {\\n          point._bufferIndex = 0;\\n        }\\n\\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\\n          go(chunk.charCodeAt(point._bufferIndex));\\n        }\\n      } else {\\n        go(chunk);\\n      }\\n    }\\n  }\\n  /**\\n   * Deal with one code.\\n   *\\n   * @param {Code} code\\n   * @returns {void}\\n   */\\n\\n\\n  function go(code) {\\n    consumed = undefined;\\n    expectedCode = code;\\n    state = state(code);\\n  }\\n  /** @type {Effects['consume']} */\\n\\n\\n  function consume(code) {\\n    if ((0, _micromarkUtilCharacter.markdownLineEnding)(code)) {\\n      point.line++;\\n      point.column = 1;\\n      point.offset += code === -3 ? 2 : 1;\\n      accountForPotentialSkip();\\n    } else if (code !== -1) {\\n      point.column++;\\n      point.offset++;\\n    } // Not in a string chunk.\\n\\n\\n    if (point._bufferIndex < 0) {\\n      point._index++;\\n    } else {\\n      point._bufferIndex++; // At end of string chunk.\\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\\n      // strings.\\n\\n      if (point._bufferIndex === chunks[point._index].length) {\\n        point._bufferIndex = -1;\\n        point._index++;\\n      }\\n    } // Expose the previous character.\\n\\n\\n    context.previous = code; // Mark as consumed.\\n\\n    consumed = true;\\n  }\\n  /** @type {Effects['enter']} */\\n\\n\\n  function enter(type, fields) {\\n    /** @type {Token} */\\n    // @ts-expect-error Patch instead of assign required fields to help GC.\\n    const token = fields || {};\\n    token.type = type;\\n    token.start = now();\\n    context.events.push(['enter', token, context]);\\n    stack.push(token);\\n    return token;\\n  }\\n  /** @type {Effects['exit']} */\\n\\n\\n  function exit(type) {\\n    const token = stack.pop();\\n    token.end = now();\\n    context.events.push(['exit', token, context]);\\n    return token;\\n  }\\n  /**\\n   * Use results.\\n   *\\n   * @type {ReturnHandle}\\n   */\\n\\n\\n  function onsuccessfulconstruct(construct, info) {\\n    addResult(construct, info.from);\\n  }\\n  /**\\n   * Discard results.\\n   *\\n   * @type {ReturnHandle}\\n   */\\n\\n\\n  function onsuccessfulcheck(_, info) {\\n    info.restore();\\n  }\\n  /**\\n   * Factory to attempt/check/interrupt.\\n   *\\n   * @param {ReturnHandle} onreturn\\n   * @param {Record<string, unknown>} [fields]\\n   */\\n\\n\\n  function constructFactory(onreturn, fields) {\\n    return hook;\\n    /**\\n     * Handle either an object mapping codes to constructs, a list of\\n     * constructs, or a single construct.\\n     *\\n     * @param {Construct|Array<Construct>|ConstructRecord} constructs\\n     * @param {State} returnState\\n     * @param {State} [bogusState]\\n     * @returns {State}\\n     */\\n\\n    function hook(constructs, returnState, bogusState) {\\n      /** @type {Array<Construct>} */\\n      let listOfConstructs;\\n      /** @type {number} */\\n\\n      let constructIndex;\\n      /** @type {Construct} */\\n\\n      let currentConstruct;\\n      /** @type {Info} */\\n\\n      let info;\\n      return Array.isArray(constructs) ?\\n      /* c8 ignore next 1 */\\n      handleListOfConstructs(constructs) : 'tokenize' in constructs // @ts-expect-error Looks like a construct.\\n      ? handleListOfConstructs([constructs]) : handleMapOfConstructs(constructs);\\n      /**\\n       * Handle a list of construct.\\n       *\\n       * @param {ConstructRecord} map\\n       * @returns {State}\\n       */\\n\\n      function handleMapOfConstructs(map) {\\n        return start;\\n        /** @type {State} */\\n\\n        function start(code) {\\n          const def = code !== null && map[code];\\n          const all = code !== null && map.null;\\n          const list = [// To do: add more extension tests.\\n\\n          /* c8 ignore next 2 */\\n          ...(Array.isArray(def) ? def : def ? [def] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\\n          return handleListOfConstructs(list)(code);\\n        }\\n      }\\n      /**\\n       * Handle a list of construct.\\n       *\\n       * @param {Array<Construct>} list\\n       * @returns {State}\\n       */\\n\\n\\n      function handleListOfConstructs(list) {\\n        listOfConstructs = list;\\n        constructIndex = 0;\\n\\n        if (list.length === 0) {\\n          return bogusState;\\n        }\\n\\n        return handleConstruct(list[constructIndex]);\\n      }\\n      /**\\n       * Handle a single construct.\\n       *\\n       * @param {Construct} construct\\n       * @returns {State}\\n       */\\n\\n\\n      function handleConstruct(construct) {\\n        return start;\\n        /** @type {State} */\\n\\n        function start(code) {\\n          // To do: not needed to store if there is no bogus state, probably?\\n          // Currently doesn\\u2019t work because `inspect` in document does a check\\n          // w/o a bogus, which doesn\\u2019t make sense. But it does seem to help perf\\n          // by not storing.\\n          info = store();\\n          currentConstruct = construct;\\n\\n          if (!construct.partial) {\\n            context.currentConstruct = construct;\\n          }\\n\\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\\n            return nok(code);\\n          }\\n\\n          return construct.tokenize.call( // If we do have fields, create an object w/ `context` as its\\n          // prototype.\\n          // This allows a \\u201clive binding\\u201d, which is needed for `interrupt`.\\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\\n        }\\n      }\\n      /** @type {State} */\\n\\n\\n      function ok(code) {\\n        consumed = true;\\n        onreturn(currentConstruct, info);\\n        return returnState;\\n      }\\n      /** @type {State} */\\n\\n\\n      function nok(code) {\\n        consumed = true;\\n        info.restore();\\n\\n        if (++constructIndex < listOfConstructs.length) {\\n          return handleConstruct(listOfConstructs[constructIndex]);\\n        }\\n\\n        return bogusState;\\n      }\\n    }\\n  }\\n  /**\\n   * @param {Construct} construct\\n   * @param {number} from\\n   * @returns {void}\\n   */\\n\\n\\n  function addResult(construct, from) {\\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\\n      resolveAllConstructs.push(construct);\\n    }\\n\\n    if (construct.resolve) {\\n      (0, _micromarkUtilChunked.splice)(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\\n    }\\n\\n    if (construct.resolveTo) {\\n      context.events = construct.resolveTo(context.events, context);\\n    }\\n  }\\n  /**\\n   * Store state.\\n   *\\n   * @returns {Info}\\n   */\\n\\n\\n  function store() {\\n    const startPoint = now();\\n    const startPrevious = context.previous;\\n    const startCurrentConstruct = context.currentConstruct;\\n    const startEventsIndex = context.events.length;\\n    const startStack = Array.from(stack);\\n    return {\\n      restore,\\n      from: startEventsIndex\\n    };\\n    /**\\n     * Restore state.\\n     *\\n     * @returns {void}\\n     */\\n\\n    function restore() {\\n      point = startPoint;\\n      context.previous = startPrevious;\\n      context.currentConstruct = startCurrentConstruct;\\n      context.events.length = startEventsIndex;\\n      stack = startStack;\\n      accountForPotentialSkip();\\n    }\\n  }\\n  /**\\n   * Move the current point a bit forward in the line when it\\u2019s on a column\\n   * skip.\\n   *\\n   * @returns {void}\\n   */\\n\\n\\n  function accountForPotentialSkip() {\\n    if (point.line in columnStart && point.column < 2) {\\n      point.column = columnStart[point.line];\\n      point.offset += columnStart[point.line] - 1;\\n    }\\n  }\\n}\\n/**\\n * Get the chunks from a slice of chunks in the range of a token.\\n *\\n * @param {Array<Chunk>} chunks\\n * @param {Pick<Token, 'start'|'end'>} token\\n * @returns {Array<Chunk>}\\n */\\n\\n\\nfunction sliceChunks(chunks, token) {\\n  const startIndex = token.start._index;\\n  const startBufferIndex = token.start._bufferIndex;\\n  const endIndex = token.end._index;\\n  const endBufferIndex = token.end._bufferIndex;\\n  /** @type {Array<Chunk>} */\\n\\n  let view;\\n\\n  if (startIndex === endIndex) {\\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\\n  } else {\\n    view = chunks.slice(startIndex, endIndex);\\n\\n    if (startBufferIndex > -1) {\\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\\n      view[0] = view[0].slice(startBufferIndex);\\n    }\\n\\n    if (endBufferIndex > 0) {\\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\\n    }\\n  }\\n\\n  return view;\\n}\\n/**\\n * Get the string value of a slice of chunks.\\n *\\n * @param {Array<Chunk>} chunks\\n * @param {boolean} [expandTabs=false]\\n * @returns {string}\\n */\\n\\n\\nfunction serializeChunks(chunks, expandTabs) {\\n  let index = -1;\\n  /** @type {Array<string>} */\\n\\n  const result = [];\\n  /** @type {boolean|undefined} */\\n\\n  let atTab;\\n\\n  while (++index < chunks.length) {\\n    const chunk = chunks[index];\\n    /** @type {string} */\\n\\n    let value;\\n\\n    if (typeof chunk === 'string') {\\n      value = chunk;\\n    } else switch (chunk) {\\n      case -5:\\n        {\\n          value = '\\\\r';\\n          break;\\n        }\\n\\n      case -4:\\n        {\\n          value = '\\\\n';\\n          break;\\n        }\\n\\n      case -3:\\n        {\\n          value = '\\\\r' + '\\\\n';\\n          break;\\n        }\\n\\n      case -2:\\n        {\\n          value = expandTabs ? ' ' : '\\\\t';\\n          break;\\n        }\\n\\n      case -1:\\n        {\\n          if (!expandTabs && atTab) continue;\\n          value = ' ';\\n          break;\\n        }\\n\\n      default:\\n        {\\n          // Currently only replacement character.\\n          value = String.fromCharCode(chunk);\\n        }\\n    }\\n\\n    atTab = chunk === -2;\\n    result.push(value);\\n  }\\n\\n  return result.join('');\\n}\\n};\"],\n\"names\":[\"shadow$provide\",\"global\",\"require\",\"module\",\"exports\",\"Object\",\"defineProperty\",\"value\",\"createTokenizer\",\"parser\",\"initialize\",\"from\",\"sliceStream\",\"token\",\"chunks\",\"startIndex\",\"start\",\"_index\",\"startBufferIndex\",\"_bufferIndex\",\"endIndex\",\"end\",\"endBufferIndex\",\"view\",\"slice\",\"push\",\"now\",\"assign\",\"point\",\"onsuccessfulcheck\",\"_\",\"info\",\"restore\",\"constructFactory\",\"onreturn\",\"fields\",\"hook\",\"constructs\",\"returnState\",\"bogusState\",\"handleMapOfConstructs\",\"map\",\"code\",\"def\",\"all\",\"null\",\"list\",\"Array\",\"isArray\",\"handleListOfConstructs\",\"listOfConstructs\",\"constructIndex\",\"length\",\"handleConstruct\",\"construct\",\"store\",\"currentConstruct\",\"partial\",\"context\",\"name\",\"disable\",\"includes\",\"nok\",\"tokenize\",\"call\",\"create\",\"effects\",\"ok\",\"addResult\",\"resolveAll\",\"resolveAllConstructs\",\"resolve\",\"_micromarkUtilChunked\",\"splice\",\"events\",\"resolveTo\",\"startPoint\",\"startPrevious\",\"previous\",\"startCurrentConstruct\",\"startEventsIndex\",\"startStack\",\"stack\",\"accountForPotentialSkip\",\"line\",\"columnStart\",\"column\",\"offset\",\"consume\",\"_micromarkUtilCharacter\",\"markdownLineEnding\",\"enter\",\"type\",\"exit\",\"pop\",\"attempt\",\"onsuccessfulconstruct\",\"check\",\"interrupt\",\"containerState\",\"sliceSerialize\",\"expandTabs\",\"index\",\"result\",\"atTab\",\"chunk\",\"String\",\"fromCharCode\",\"join\",\"defineSkip\",\"write\",\"chunkIndex\",\"state\",\"charCodeAt\",\"_micromarkUtilResolveAll\"]\n}\n"]